env: 'prod'

psmdb-db:
  # Default values for psmdb-cluster.
  # This is a YAML-formatted file.
  # Declare variables to be passed into your templates.

  # Platform type: kubernetes, openshift
  platform: kubernetes

  # Cluster DNS Suffix
  clusterServiceDNSSuffix: svc.cluster.local
  # clusterServiceDNSMode: "Internal"

  finalizers:
  ## Set this if you want that operator deletes the primary pod last
    - percona.com/delete-psmdb-pods-in-order
  ## Set this if you want to delete database persistent volumes on cluster deletion
  #  - percona.com/delete-psmdb-pvc
  ## Set this if you want to delete all pitr chunks on cluster deletion
  #  - percona.com/delete-pitr-chunks

  nameOverride: ""
  fullnameOverride: ""

  annotations:
    argocd.argoproj.io/sync-wave: '10'

  crVersion: 1.19.1
  pause: false
  unmanaged: false

  unsafeFlags:
    tls: false
    replsetSize: false
    mongosSize: false
    terminationGracePeriod: false
    backupIfUnhealthy: false

  enableVolumeExpansion: false

  # ignoreAnnotations:
  #   - service.beta.kubernetes.io/aws-load-balancer-backend-protocol
  # ignoreLabels:
  #   - rack

  #
  # TODO: Setup mutlicluster MongoDB
  #
  multiCluster:
    enabled: false
    # DNSSuffix: svc.clusterset.local

  updateStrategy: SmartUpdate
  upgradeOptions:
    versionServiceEndpoint: https://check.percona.com
    apply: disabled
    schedule: "0 2 * * *"
    setFCV: false

  imagePullPolicy: Always

  tls:
    mode: preferTLS
  #   # 90 days in hours
  #   certValidityDuration: 2160h
  #   allowInvalidCertificates: true
  #   issuerConf:
  #     name: special-selfsigned-issuer
  #     kind: ClusterIssuer
  #     group: cert-manager.io
  secrets:
    # If you set users secret here the operator will use existing one or generate random values
    # If not set the operator generates the default secret with name <cluster_name>-secrets
    # users: my-cluster-name-secrets
    # encryptionKey: my-cluster-name-mongodb-encryption-key
    ssl: myloginspace-default-certificates
    # sslInternal: my-cluster-name-ssl-internal
    # keyFile: my-cluster-name-mongodb-keyfile
    # vault: my-cluster-name-vault
    ldapSecret: my-ldap-secret
    # sse: my-cluster-name-sse

  pmm:
    enabled: false
    image:
      repository: percona/pmm-client

    serverHost: monitoring-service


  replsets:
    rs0:
      name: rs0
      size: 3

      affinity: {}

      priorityClass: 'tier2-priority'

      # storage:
      #   engine: wiredTiger
      #   wiredTiger:
      #     engineConfig:
      #       cacheSizeRatio: 0.5
      #       directoryForIndexes: false
      #       journalCompressor: snappy
      #     collectionConfig:
      #       blockCompressor: snappy
      #     indexConfig:
      #       prefixCompression: true
      #   inMemory:
      #     engineConfig:
      #        inMemorySizeRatio: 0.5

      expose:
        enabled: false
        type: ClusterIP
        # loadBalancerIP: 10.0.0.0
        # loadBalancerSourceRanges:
        #   - 10.0.0.0/8
        # annotations:
        #   service.beta.kubernetes.io/aws-load-balancer-backend-protocol: http
        # labels:
        #   some-label: some-key
        # internalTrafficPolicy: Local
        # externalTrafficPolicy: Local
      # schedulerName: ""
      resources:
        limits:
          cpu: '300m'
          memory: '0.5G'
        requests:
          cpu: '300m'
          memory: '0.5G'
      volumeSpec:
        pvc:
          labels:
            resolvemy.host/env: 'prod'
          resources:
            requests:
              storage: 3Gi

      nonvoting:
        enabled: false

      arbiter:
        enabled: false
        size: 1


  sharding:
    enabled: false
    balancer:
      enabled: true


  # users:
  # - name: my-user
  #   db: admin
  #   passwordSecretRef:
  #     name: my-user-password
  #     key: my-user-password-key
  #   roles:
  #     - name: clusterAdmin
  #       db: admin
  #     - name: userAdminAnyDatabase
  #       db: admin
  # - name: my-usr
  #   db: admin
  #   passwordSecretRef:
  #     name: my-user-pwd
  #     key: my-user-pwd-key
  #   roles:
  #     - name: dbOwner
  #       db: sometest

  #  roles:
  #    - role: myClusterwideAdmin
  #      db: admin
  #      privileges:
  #        - resource:
  #            cluster: true
  #          actions:
  #            - addShard
  #        - resource:
  #            db: config
  #            collection: ''
  #          actions:
  #            - find
  #            - update
  #            - insert
  #            - remove
  #      roles:
  #        - role: read
  #          db: admin
  #    - role: my-role
  #      db: myDb
  #      privileges:
  #        - resource:
  #            db: ''
  #            collection: ''
  #          actions:
  #            - find
  #      authenticationRestrictions:
  #        - clientSource:
  #            - 127.0.0.1
  #          serverAddress:
  #            - 127.0.0.1


  backup:
    enabled: true

    # resources:
    #   limits:
    #     cpu: "300m"
    #     memory: "1.2G"
    #   requests:
    #     cpu: "300m"
    #     memory: "1G"
    storages:
      core-minio:
        type: s3
        s3:
          bucket: mongodb-backups
          region: us-east-1
          endpointUrl: https://s3.mylogin.space

    pitr:
      enabled: true
      oplogOnly: false
      # oplogSpanMin: 10
      # compressionType: gzip
      # compressionLevel: 6
    # configuration:
    #   backupOptions:
    #     priority:
    #       "localhost:28019": 2.5
    #       "localhost:27018": 2.5
    #     timeouts:
    #       startingStatus: 33
    #     oplogSpanMin: 10
    #   restoreOptions:
    #     batchSize: 500
    #     numInsertionWorkers: 10
    #     numDownloadWorkers: 4
    #     maxDownloadBufferMb: 0
    #     downloadChunkMb: 32
    #     mongodLocation: /usr/bin/mongo
    #     mongodLocationMap:
    #       "node01:2017": /usr/bin/mongo
    #       "node03:27017": /usr/bin/mongo
    tasks:
      - name: daily-s3-minio
        enabled: true
        schedule: "0 0 * * *"
        keep: 3
        storageName: core-minio
        compressionType: gzip
    # - name: weekly-s3-us-west
    #   enabled: false
    #   schedule: "0 0 * * 0"
    #   keep: 5
    #   storageName: s3-us-west
    #   compressionType: gzip
    # - name: weekly-s3-us-west-physical
    #   enabled: false
    #   schedule: "0 5 * * 0"
    #   keep: 5
    #   type: physical
    #   storageName: s3-us-west
    #   compressionType: gzip
    #   compressionLevel: 6

  # If you set systemUsers here the secret will be constructed by helm with these values
  # systemUsers:
  #   MONGODB_BACKUP_USER: backup
  #   MONGODB_BACKUP_PASSWORD: backup123456
  #   MONGODB_DATABASE_ADMIN_USER: databaseAdmin
  #   MONGODB_DATABASE_ADMIN_PASSWORD: databaseAdmin123456
  #   MONGODB_CLUSTER_ADMIN_USER: clusterAdmin
  #   MONGODB_CLUSTER_ADMIN_PASSWORD: clusterAdmin123456
  #   MONGODB_CLUSTER_MONITOR_USER: clusterMonitor
  #   MONGODB_CLUSTER_MONITOR_PASSWORD: clusterMonitor123456
  #   MONGODB_USER_ADMIN_USER: userAdmin
  #   MONGODB_USER_ADMIN_PASSWORD: userAdmin123456
  #   PMM_SERVER_API_KEY: apikey
  #   # PMM_SERVER_USER: admin
  #   # PMM_SERVER_PASSWORD: admin
