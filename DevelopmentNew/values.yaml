argo-cd:
  enabled: false

artifact-hub:
  enabled: true

  fullnameOverride: artifacthub-prod

  postgresql:
    enabled: false

  db:
    host: psql.service.dc1.kjdev
    port: '5432'
    database: <secret:CORE0_SITE1/data/ArtifactHub~DatabaseDatabase>
    user: <secret:CORE0_SITE1/data/ArtifactHub~DatabaseUsername>
    password: <secret:CORE0_SITE1/data/ArtifactHub~DatabasePassword>

  # Hub configuration
  hub:
    ingress:
      enabled: false

    service:
      type: ClusterIP
      port: 80

    deploy:
      readinessGates: []

      replicaCount: 2

      image:
        # Hub image repository (without the tag)
        repository: artifacthub/hub

      resources: {}

    server:
      # Allow adding private repositories to the Hub
      allowPrivateRepositories: false

      # Cache directory path. If set, the cache directory for the Helm client will be explicitly set (otherwise
      # defaults to $HOME/.cache), and the directory will be mounted as ephemeral volume (emptyDir)
      cacheDir: ''

      # Directory path where the configuration files should be mounted
      configDir: '/home/hub/.cfg'

      # Hub server base url
      baseURL: artifacthub.int.mylogin.space

      # Hub server shutdown timeout
      shutdownTimeout: 10s

      # Message of the day. The message of the day will be displayed in a banner on the top of the Artifact Hub UI
      motd: ''

      # Message of the day severity. The color used for the banner will be based on the severity selected
      # Options: "info", "warning", "error"
      motdSeverity: info

      basicAuth:
        # Enable Hub basic auth
        enabled: false

      cookie:
        # Hub cookie hash key
        hashKey: default-unsafe-key

        # Enable Hub secure cookies
        secure: false

      csrf:
        # CSRF authentication key
        authKey: default-unsafe-key
        # CSRF secure cookie
        secure: false

      oauth:
        oidc:
          # Enable OIDC
          enabled: true

          # OpenID connect issuer url
          issuerURL: https://idp.mylogin.space/application/o/k0s-dc1/

          # OpenID connect oauth client id
          clientID: <secret:CORE0_SITE1/data/ArtifactHub~OpenIDClientID>

          # OpenID connect oauth client secret
          clientSecret: <secret:CORE0_SITE1/data/ArtifactHub~OpenIDClientSecret>

          # OpenID connect oauth redirect url
          redirectURL: https://artifacthub.int.mylogin.space/oauth/oidc/callback

          # OpenID connect oauth scopes
          scopes:
            - openid
            - profile
            - email

          # Skip email verified check
          skipEmailVerifiedCheck: false

      # X-Forwarded-For IP index
      xffIndex: 0

    analytics:
      # Google Analytics tracking id
      gaTrackingID: ""

    theme:
      # Colors used in the website
      colors:
        # Primary color used in the website. For an optimal experience, it's better to use colors that play well with
        # white fonts
        primary: '#417598'

        # Secondary color used in the website, usually a darker version of the primary color. For an optimal experience,
        # it's better to use colors that play well with white fonts
        secondary: '#2D4857'

      # Images used in the website
      images:
        # URL of the image used for the Apple touch icon (192x192)
        appleTouchIcon192: '/static/media/logo192_v2.png'

        # URL of the image used for the Apple touch icon (512x512)
        appleTouchIcon512: '/static/media/logo512_v2.png'

        # URL of the image used in the og:image tag. This image is displayed when an Artifact Hub link is shared in
        # Twitter or Slack, for example. The URL must use `https`
        openGraphImage: '/static/media/artifactHub_v2.png'

        # URL of the image used for the shortcut icon (also known as favicon)
        shortcutIcon: '/static/media/logo_v2.png'

        # URL of the logo used in the website header. For an optimal experience, it's better to use a white logo with
        # transparent background, with no margin around it. It'll be displayed using a maximum height of 20px and a
        # maximum width of 185px
        websiteLogo: '/static/media/logo/artifacthub-brand-white.svg'

      # Sample search queries used in home and no results found pages
      sampleQueries: []
      # Name of the site. This name is displayed in some places in the website and email templates. When a different
      # value than the default one (Artifact Hub) is provided, the site enters `white label` mode. In this mode, some
      # sections of the website are displayed in a more generic way, omitting certain parts that are unique to Artifact Hub
      siteName: 'CoRE Artifact hub'

  log:
    level: error
    pretty: false

  tracker:
    cronjob:
      image:
        repository: artifacthub/tracker
    cacheDir: ''
    configDir: '/home/tracker/.cfg'
    concurrency: 1

#
# TODO
#

reflector:
  # Default values for reflector.
  # This is a YAML-formatted file.
  # Declare variables to be passed into your templates.

  replicaCount: 1

  image:
    repository: emberstack/kubernetes-reflector
    pullPolicy: IfNotPresent
    # Overrides the image tag whose default is the chart appVersion.

  imagePullSecrets: []
  nameOverride: ''
  fullnameOverride: ''

  configuration:
    logging:
      minimumLevel: Information

    watcher:
      timeout: ''

  rbac:
    enabled: true

  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""

  podAnnotations: {}

  podSecurityContext:
    fsGroup: 2000

  securityContext:
    capabilities:
      drop:
        - ALL
    readOnlyRootFilesystem: false
    runAsNonRoot: true
    runAsUser: 1000

  livenessProbe:
    initialDelaySeconds: 5
    periodSeconds: 10

  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 10
  startupProbe:
    # The application will have a maximum of 50s (10 * 5 = 50s) to finish its startup.
    failureThreshold: 10
    periodSeconds: 5

  resources:
    {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80

  nodeSelector: {}

  tolerations: []

  affinity: {}

  priorityClassName: ''


gitlab:
  enabled: false

  ## NOTICE
  #
  # Due to the scope and complexity of this chart, all possible values are
  # not documented in this file. Extensive documentation is available.
  #
  # Please read the docs: https://docs.gitlab.com/charts/
  #
  # Because properties are regularly added, updated, or relocated, it is
  # _strongly suggest_ to not "copy and paste" this YAML. Please provide
  # Helm only those properties you need, and allow the defaults to be
  # provided by the version of this chart at the time of deployment.

  ## Advanced Configuration
  ## https://docs.gitlab.com/charts/advanced
  #
  # Documentation for advanced configuration, such as
  # - External PostgreSQL
  # - External Gitaly
  # - External Redis
  # - External NGINX
  # - External Object Storage providers
  # - PersistentVolume configuration

  ## The global properties are used to configure multiple charts at once.
  ## https://docs.gitlab.com/charts/charts/globals
  global:
    common:
      labels: {}

    image: {}
      # pullPolicy: IfNotPresent
      # pullSecrets: []

    ## Supplemental Pod labels. Will not be used for selectors.
    pod:
      labels: {}

    ## https://docs.gitlab.com/charts/installation/deployment#deploy-the-community-edition
    edition: ee

    ## https://docs.gitlab.com/charts/charts/globals#gitlab-version
    # gitlabVersion:

    ## https://docs.gitlab.com/charts/charts/globals#application-resource
    application:
      create: false
      links: []
      allowClusterRoles: true

    ## https://docs.gitlab.com/charts/charts/globals#configure-host-settings
    hosts:
      domain: writemy.codes

      hostSuffix:

      https: true

      externalIP:

      ssh: ~

      gitlab: {}

      minio: {}

      registry: {}

      tls: {}

      smartcard: {}

      kas: {}

      pages: {}

    ## https://docs.gitlab.com/charts/charts/globals#configure-ingress-settings
    ingress:
      apiVersion: ''
      configureCertmanager: true

      provider: traefik

      # class:
      annotations: {}

      enabled: true

      tls: {}
      #   enabled: true
      #   secretName:

      path: /

      pathType: Prefix

    gitlab:
      ## Enterprise license for this GitLab installation
      ## Secret created according to https://docs.gitlab.com/charts/installation/secrets#initial-enterprise-license
      ## If allowing shared-secrets generation, this is OPTIONAL.
      license: {}
        # secret: RELEASE-gitlab-license
        # key: license

    ## Initial root password for this GitLab installation
    ## Secret created according to https://docs.gitlab.com/charts/installation/secrets#initial-root-password
    ## If allowing shared-secrets generation, this is OPTIONAL.
    initialRootPassword: {}
      # secret: RELEASE-gitlab-initial-root-password
      # key: password


    ## https://docs.gitlab.com/charts/charts/globals#configure-postgresql-settings
    psql:
      connectTimeout:
      keepalives:
      keepalivesIdle:
      keepalivesInterval:
      keepalivesCount:
      tcpUserTimeout:
      password:
        useSecret: true
        secret: gitlab-database-prod
        key: DatabasePassword
      host: psql.service.dc1.kjdev
      # port: 123
      
      username: <secret:CORE0_SITE1/data/GitLab~PraefectDatabase>
      database: <secret:CORE0_SITE1/data/GitLab~PraefectDatabase>
      # applicationName:
      preparedStatements: true
      databaseTasks: true


    ## https://docs.gitlab.com/charts/charts/globals#configure-redis-settings
    redis:
      password:
        enabled: false

      host: 10.1.1.68
      port: 6379
      # sentinels:
      #   - host:
      #     port:


    ## https://docs.gitlab.com/charts/charts/globals#configure-gitaly-settings
    gitaly:
      enabled: true

      authToken: {}
        # secret:
        # key:

      # serviceName:
      internal:
        names: [default]

      external: []

      service:
        name: gitaly

        type: ClusterIP

        externalPort: 8075
        internalPort: 8075

        tls:
          externalPort: 8076
          internalPort: 8076

      tls:
        enabled: false
        # secretName:


    praefect:
      enabled: true

      replaceInternalGitaly: true

      authToken: {}

      autoMigrate: true

      dbSecret:
        key: DatabasePassword
        secret: gitlab-praefect-database-{{ environment }}

      virtualStorages:
        - name: default
          gitalyReplicas: 3
          maxUnavailable: 1

      psql:
        dbName: <secret:CORE0_SITE1/data/GitLab~PraefectDatabase>
        host: psql.service.dc1.kjdev
        port: 5432
        user: <secret:CORE0_SITE1/data/GitLab~PraefectDatabase>

      service:
        name: praefect

        type: ClusterIP

        externalPort: 8075
        internalPort: 8075

        tls:
          externalPort: 8076
          internalPort: 8076

      tls:
        enabled: false
        # secretName:


    ## https://docs.gitlab.com/charts/charts/globals#configure-minio-settings
    minio:
      enabled: false


    ## https://docs.gitlab.com/charts/charts/globals#configure-grafana-integration
    grafana:
      enabled: false


    ## https://docs.gitlab.com/charts/charts/globals#configure-appconfig-settings
    ## Rails based portions of this chart share many settings
    appConfig:
      ## https://docs.gitlab.com/charts/charts/globals#general-application-settings
      enableUsagePing: true

      enableSeatLink: true

      enableImpersonation:

      applicationSettingsCacheSeconds: 60

      defaultCanCreateGroup: true

      usernameChangingEnabled: true

      issueClosingPattern:

      defaultTheme:

      defaultProjectsFeatures:
        issues: true
        mergeRequests: true
        wiki: true
        snippets: true
        builds: true

      webhookTimeout:

      maxRequestDurationSeconds:

      ## https://docs.gitlab.com/charts/charts/globals#cron-jobs-related-settings
      cron_jobs: {}
        ## Flag stuck CI builds as failed
        # stuck_ci_jobs_worker:
        #   cron: "0 * * * *"
        ## Schedule pipelines in the near future
        # pipeline_schedule_worker:
        #   cron: "19 * * * *"
        ## Remove expired build artifacts
        # expire_build_artifacts_worker:
        #   cron: "*/7 * * * *"
        ## Periodically run 'git fsck' on all repositories.
        # repository_check_worker:
        #   cron: "20 * * * *"
        ## Send admin emails once a week
        # admin_email_worker:
        #   cron: "0 0 * * 0"
        ## Remove outdated repository archives
        # repository_archive_cache_worker:
        #   cron: "0 * * * *"
        ## Verify custom GitLab Pages domains
        # pages_domain_verification_cron_worker:
        #   cron: "*/15 * * * *"
        # schedule_migrate_external_diffs_worker:
        #   cron: "15 * * * *"
        ## Prune stale group runners on opted-in namespaces
        # ci_runners_stale_group_runners_prune_worker_cron:
        #   cron: "30 * * * *"
        ### GitLab Geo
        # Geo Primary only!
        # geo_prune_event_log_worker:
        #   cron: "*/5 * * * *"
        ## GitLab Geo repository sync worker
        # geo_repository_sync_worker:
        #   cron: "*/5 * * * *"
        ## GitLab Geo file download dispatch worker
        # geo_file_download_dispatch_worker:
        #  cron: "*/10 * * * *"
        ## GitLab Geo repository verification primary batch worker
        # geo_repository_verification_primary_batch_worker:
        #   cron: "*/5 * * * *"
        ## GitLab Geo repository verification secondary scheduler worker
        # geo_repository_verification_secondary_scheduler_worker:
        #   cron: "*/5 * * * *"
        ## GitLab Geo migrated local files clean up worker
        # geo_migrated_local_files_clean_up_worker:
        #   cron: "15 */6 * * *"
        ### LDAP
        # ldap_sync_worker:
        #   cron: "30 1 * * *"
        # ldap_group_sync_worker:
        #   cron: "0 * * * *"
        ### Snapshot active user statistics
        # historical_data_worker:
        #   cron: "0 12 * * *"
        # loose_foreign_keys_cleanup_worker_cron:
        #   cron: "*/5 * * * *"

      ## https://docs.gitlab.com/charts/charts/globals#content-security-policy
      contentSecurityPolicy:
        enabled: false
        report_only: true
        # directives: {}


      ## https://docs.gitlab.com/charts/charts/globals#gravatarlibravatar-settings
      gravatar:
        plainUrl:
        sslUrl:


      ## https://docs.gitlab.com/charts/charts/globals#hooking-analytics-services-to-the-gitlab-instance
      extra:
        googleAnalyticsId:
        matomoUrl:
        matomoSiteId:
        matomoDisableCookies:
        oneTrustId:
        googleTagManagerNonceId:
        bizible:


      ## https://docs.gitlab.com/charts/charts/globals#lfs-artifacts-uploads-packages-external-mr-diffs-and-dependency-proxy
      object_store:
        enabled: false

        proxy_download: true

        storage_options: {}
          # server_side_encryption:
          # server_side_encryption_kms_key_id
        connection: {}
          # secret:
          # key:

      lfs:
        enabled: true

        proxy_download: true

        bucket: git-lfs

        connection: {}
          # secret:
          # key:

      artifacts:
        enabled: true
        proxy_download: true
        bucket: gitlab-artifacts
        connection: {}
          # secret:
          # key:

      uploads:
        enabled: true
        proxy_download: true
        bucket: gitlab-uploads
        connection: {}
          # secret:
          # key:

      packages:
        enabled: true
        proxy_download: true
        bucket: gitlab-packages
        connection: {}

      externalDiffs:
        enabled: false
        when:
        proxy_download: true
        bucket: gitlab-mr-diffs
        connection: {}

      terraformState:
        enabled: false
        bucket: gitlab-terraform-state
        connection: {}

      ciSecureFiles:
        enabled: false
        bucket: gitlab-ci-secure-files
        connection: {}

      dependencyProxy:
        enabled: false
        proxy_download: true
        bucket: gitlab-dependency-proxy
        connection: {}

      backups:
        bucket: gitlab-backups
        tmpBucket: tmp


      ## https://docs.gitlab.com/charts/installation/command-line-options.html#incoming-email-configuration
      ## https://docs.gitlab.com/charts/charts/gitlab/mailroom/index.html#incoming-email
      incomingEmail:
        enabled: false

        address: ""

        host: "imap.gmail.com"

        port: 993

        ssl: true

        startTls: false

        user: ""

        password:
          secret: ""
          key: password

        expungeDeleted: false

        logger:
          logPath: "/dev/stdout"

        mailbox: inbox

        idleTimeout: 60

        inboxMethod: "imap"

        clientSecret:
          key: secret

        pollInterval: 60

        deliveryMethod: sidekiq

        authToken: {}
          # secret:
          # key:


      ## https://docs.gitlab.com/charts/charts/gitlab/mailroom/index.html#service-desk-email
      serviceDeskEmail:
        enabled: false
        address: ''
        host: 'imap.gmail.com'
        port: 993
        ssl: true
        startTls: false
        user: ""
        password:
          secret: ""
          key: password
        expungeDeleted: false
        logger:
          logPath: "/dev/stdout"
        mailbox: inbox
        idleTimeout: 60
        inboxMethod: "imap"
        clientSecret:
          key: secret
        pollInterval: 60
        deliveryMethod: sidekiq
        authToken: {}
          # secret:
          # key:

      ## https://docs.gitlab.com/charts/charts/globals#ldap
      ldap:
        # prevent the use of LDAP for sign-in via web.
        preventSignin: false
        servers: {}
        ## See documentation for complete example of a configured LDAP server

      ## https://docs.gitlab.com/charts/charts/globals#kas-settings
      gitlab_kas: {}
        # secret:
        # key:
        # enabled:
        # externalUrl:
        # internalUrl:

      ## https://docs.gitlab.com/charts/charts/globals#omniauth
      omniauth:
        enabled: false
        autoSignInWithProvider:
        syncProfileFromProvider: []
        syncProfileAttributes: [email]
        allowSingleSignOn: [saml]
        blockAutoCreatedUsers: true
        autoLinkLdapUser: false
        autoLinkSamlUser: false
        autoLinkUser: []
        externalProviders: []
        allowBypassTwoFactor: []
        providers: []
        # - secret: gitlab-google-oauth2
        #   key: provider

      ## https://docs.gitlab.com/charts/charts/globals#configure-appconfig-settings
      sentry:
        enabled: false
        dsn:
        clientside_dsn:
        environment:


      smartcard:
        enabled: false
        CASecret:
        clientCertificateRequiredHost:
        sanExtensions: false
        requiredForGitAccess: false


      sidekiq:
        routingRules: []

      # Config that only applies to the defaults on initial install
      initialDefaults: {}
        # signupEnabled:
    ## End of global.appConfig

    oauth:
      gitlab-pages: {}
        # secret:
        # appIdKey:
        # appSecretKey:
        # redirectUri:
        # authScope:

    ## https://docs.gitlab.com/charts/advanced/geo/
    geo:
      enabled: false
      # Valid values: primary, secondary
      role: primary
      ## Geo Secondary only
      # nodeName allows multiple instances behind a load balancer.
      nodeName: # defaults to `gitlab.gitlab.host`
      # PostgreSQL connection details only needed for `secondary`
      psql:
        password: {}
        #   secret:
        #   key:
        # host: postgresql.hostedsomewhere.else
        # port: 123
        # username: gitlab_replicator
        # database: gitlabhq_geo_production
        # ssl:
        #   secret:
        #   clientKey:
        #   clientCertificate:
        #   serverCA:

      registry:
        replication:
          enabled: false
          primaryApiUrl:
          ## Consumes global.registry.notificationSecret

    ## https://docs.gitlab.com/charts/charts/gitlab/kas/
    kas:
      enabled: true
      service:
        apiExternalPort: 8153 # port for connections from the GitLab backend

    ## https://docs.gitlab.com/charts/charts/gitlab/spamcheck/
    spamcheck:
      enabled: false

    ## https://docs.gitlab.com/charts/charts/globals#configure-gitlab-shell
    shell:
      authToken: {}
      # secret:
      # key:
      hostKeys: {}
        # secret:
      ## https://docs.gitlab.com/charts/charts/globals#tcp-proxy-protocol
      tcp:
        proxyProtocol: false

    ## Rails application secrets
    ## Secret created according to https://docs.gitlab.com/charts/installation/secrets#gitlab-rails-secret
    ## If allowing shared-secrets generation, this is OPTIONAL.
    railsSecrets: {}
      # secret:

    ## Rails generic setting, applicable to all Rails-based containers
    rails:
      bootsnap: # Enable / disable Shopify/Bootsnap cache
        enabled: true

    ## https://docs.gitlab.com/charts/charts/globals#configure-registry-settings
    registry:
      bucket: registry
      certificate: {}
        # secret:
      httpSecret: {}
        # secret:
        # key:
      notificationSecret: {}
        # secret:
        # key:
      # https://docs.docker.com/registry/notifications/#configuration
      notifications: {}
        # endpoints:
        #   - name: FooListener
        #     url: https://foolistener.com/event
        #     timeout: 500ms
        #     threshold: 10
        #     backoff: 1s
        #     headers:
        #       FooBar: ['1', '2']
        #       Authorization:
        #         secret: gitlab-registry-authorization-header
        #       SpecificPassword:
        #         secret: gitlab-registry-specific-password
        #         key: password
        # events: {}

    pages:
      enabled: false
      accessControl: false
      path:
      host:
      port:
      https: # default true
      externalHttp: []
      externalHttps: []
      artifactsServer: true
      localStore:
        enabled: false
        # path: /srv/gitlab/shared/pages
      objectStore:
        enabled: true
        bucket: gitlab-pages
        # proxy_download: true
        connection: {}
          # secret:
          # key:
      apiSecret: {}
        # secret:
        # key:
      authSecret: {}
        # secret:
        # key:


    ## GitLab Runner
    ## Secret created according to https://docs.gitlab.com/charts/installation/secrets#gitlab-runner-secret
    ## If allowing shared-secrets generation, this is OPTIONAL.
    runner:
      registrationToken: {}
        # secret:


    ## https://docs.gitlab.com/charts/installation/deployment#outgoing-email
    ## Outgoing email server settings
    smtp:
      enabled: false
      address: smtp.mailgun.org
      port: 2525
      user_name: ""
      ## https://docs.gitlab.com/charts/installation/secrets#smtp-password
      password:
        secret: ""
        key: password
      # domain:
      authentication: "plain"
      starttls_auto: false
      openssl_verify_mode: "peer"
      pool: false


    ## https://docs.gitlab.com/charts/installation/deployment#outgoing-email
    ## Email persona used in email sent by GitLab
    email:
      from: ""
      display_name: GitLab
      reply_to: ""
      subject_suffix: ""
      smime:
        enabled: false
        secretName: ""
        keyName: "tls.key"
        certName: "tls.crt"


    ## Timezone for containers.
    time_zone: UTC


    ## Global Service Annotations and Labels
    service:
      labels: {}
      annotations: {}

    ## Global Deployment Annotations
    deployment:
      annotations: {}

    antiAffinity: soft
    affinity:
      podAntiAffinity:
        topologyKey: "kubernetes.io/hostname"

    ## https://docs.gitlab.com/charts/charts/globals#configure-workhorse-settings
    ## Global settings related to Workhorse
    workhorse:
      serviceName: webservice-default
      # scheme:
      # host:
      # port:
      ## https://docs.gitlab.com/charts/installation/secrets#gitlab-workhorse-secret
      # secret:
      # key:

    ## https://docs.gitlab.com/charts/charts/globals#configure-webservice
    webservice:
      workerTimeout: 60


    ## https://docs.gitlab.com/charts/charts/globals#custom-certificate-authorities
    # configuration of certificates container & custom CA injection
    certificates:
      image:
        repository: registry.gitlab.com/gitlab-org/build/cng/alpine-certificates
        # The digest below comes from a given tag pipeline because they are mirrored to .com,
        # ensuring that the image tag is available from both instances. The digest can be
        # found in the 'sync_images' job.
        #   https://dev.gitlab.org/gitlab/charts/components/images/-/tags
        tag: 20191127-r2@sha256:367d437d024d7647432d67fb2442e3e5723af5930bad77d3535f4f8f4f8630d9
        # pullPolicy: IfNotPresent
        # pullSecrets: []
      customCAs: []
      # - secret: custom-CA
      # - secret: more-custom-CAs


    ## kubectl image used by hooks to carry out specific jobs
    kubectl:
      image:
        repository: registry.gitlab.com/gitlab-org/build/cng/kubectl
        # The digest below comes from a given tag pipeline because they are mirrored to .com,
        # ensuring that the image tag is available from both instances. The digest can be
        # found in the 'sync_images' job.
        #   https://dev.gitlab.org/gitlab/charts/components/images/-/tags
        tag: 1.18.20@sha256:8d27c191af306cafddba2f293c5613f8966363f779d79a5599ad0231e60069e4
        # pullPolicy: IfNotPresent
        # pullSecrets: []
      securityContext:
        # in most base images, this is `nobody:nogroup`
        runAsUser: 65534
        fsGroup: 65534
    busybox:
      image:
        repository: registry.gitlab.com/gitlab-org/cloud-native/mirror/images/busybox
        tag: latest
        # pullPolicy: IfNotPresent
        # pullSecrets: []

    ## https://docs.gitlab.com/charts/charts/globals#service-accounts
    serviceAccount:
      enabled: false
      create: true
      annotations: {}
      ## Name to be used for serviceAccount, otherwise defaults to chart fullname
      # name:

    ## https://docs.gitlab.com/charts/charts/globals/#tracing
    tracing:
      connection:
        string: ""
      urlTemplate: ""

    ## https://docs.gitlab.com/charts/charts/globals
    extraEnv: {}
    #   SOME_KEY: some_value
    #   SOME_OTHER_KEY: some_other_value

    ## https://docs.gitlab.com/charts/charts/globals
    extraEnvFrom: {}
    #   MY_NODE_NAME:
    #     fieldRef:
    #       fieldPath: spec.nodeName
    #   MY_CPU_REQUEST:
    #     resourceFieldRef:
    #       containerName: test-container
    #       resource: requests.cpu
    #   SECRET_THING:
    #     secretKeyRef:
    #       name: special-secret
    #       key: special_token
    #       # optional: boolean
    #   CONFIG_STRING:
    #     configMapKeyRef:
    #       name: useful-config
    #       key: some-string
    #       # optional: boolean
  ## End of global

  upgradeCheck:
    enabled: true

    image: {}
      # repository:
      # tag:
      # pullPolicy: IfNotPresent
      # pullSecrets: []

    securityContext:
      # in alpine/debian/busybox based images, this is `nobody:nogroup`
      runAsUser: 65534
      fsGroup: 65534

    tolerations: []

    resources:
      requests:
        cpu: 50m

  ## Settings to for the Let's Encrypt ACME Issuer
  # certmanager-issuer:
  #   # The email address to register certificates requested from Let's Encrypt.
  #   # Required if using Let's Encrypt.
  #   email: email@example.com

  ## Installation & configuration of jetstack/cert-manager
  ## See requirements.yaml for current version
  certmanager:
    installCRDs: false
    nameOverride: certmanager
    # Install cert-manager chart. Set to false if you already have cert-manager
    # installed or if you are not using cert-manager.
    install: false
    # Other cert-manager configurations from upstream
    # See https://github.com/jetstack/cert-manager/blob/master/deploy/charts/cert-manager/README#configuration
    rbac:
      create: true


  ## https://docs.gitlab.com/charts/charts/nginx/
  ## https://docs.gitlab.com/charts/architecture/decisions#nginx-ingress
  ## Installation & configuration of charts/ingress-nginx:
  nginx-ingress:
    enabled: false
    tcpExternalConfig: "true"
    controller:
      addHeaders:
        Referrer-Policy: strict-origin-when-cross-origin
      config:
        hsts: "true"
        hsts-include-subdomains: "false"
        hsts-max-age: "63072000"
        server-name-hash-bucket-size: "256"
        use-http2: "true"
        ssl-ciphers: "ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:!aNULL:!eNULL:!EXPORT:!DES:!MD5:!PSK:!RC4"
        ssl-protocols: "TLSv1.3 TLSv1.2"
        server-tokens: "false"
      service:
        externalTrafficPolicy: "Local"
      ingressClassByName: false
      ingressClassResource:
        name: '{{ include "ingress.class.name" $ }}'
      resources:
        requests:
          cpu: 100m
          memory: 100Mi
      publishService:
        enabled: true
      replicaCount: 2
      minAvailable: 1
      scope:
        enabled: true
      metrics:
        enabled: true
        service:
          annotations:
            gitlab.com/prometheus_scrape: "true"
            gitlab.com/prometheus_port: "10254"
            prometheus.io/scrape: "true"
            prometheus.io/port: "10254"
      admissionWebhooks:
        enabled: false
    defaultBackend:
      enabled: true
      minAvailable: 1
      replicaCount: 1
      resources:
        requests:
          cpu: 5m
          memory: 5Mi
    rbac:
      create: true
      # Needed for k8s 1.20 and 1.21
      # https://github.com/kubernetes/ingress-nginx/issues/7510
      # https://github.com/kubernetes/ingress-nginx/issues/7519
      scope: false
    serviceAccount:
      create: true

  ## Installation & configuration of stable/prometheus
  ## See requirements.yaml for current version
  prometheus:
    install: false
    rbac:
      create: true
    alertmanager:
      enabled: false
    alertmanagerFiles:
      alertmanager.yml: {}
    kubeStateMetrics:
      enabled: false
    nodeExporter:
      enabled: false
    pushgateway:
      enabled: false
    server:
      retention: 15d
      strategy:
        type: Recreate
    #
    serverFiles:
      prometheus.yml:
        scrape_configs:
          - job_name: prometheus
            static_configs:
              - targets:
                  - localhost:9090
          - job_name: kubernetes-apiservers
            kubernetes_sd_configs:
              - role: endpoints
            scheme: https
            tls_config:
              ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
              insecure_skip_verify: true
            bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
            relabel_configs:
              - source_labels:
                  [
                    __meta_kubernetes_namespace,
                    __meta_kubernetes_service_name,
                    __meta_kubernetes_endpoint_port_name,
                  ]
                action: keep
                regex: default;kubernetes;https
          - job_name: kubernetes-pods
            kubernetes_sd_configs:
              - role: pod
            relabel_configs:
              - source_labels:
                  [__meta_kubernetes_pod_annotation_gitlab_com_prometheus_scrape]
                action: keep
                regex: true
              - source_labels:
                  [__meta_kubernetes_pod_annotation_gitlab_com_prometheus_path]
                action: replace
                target_label: __metrics_path__
                regex: (.+)
              - source_labels:
                  [
                    __address__,
                    __meta_kubernetes_pod_annotation_gitlab_com_prometheus_port,
                  ]
                action: replace
                regex: ([^:]+)(?::\d+)?;(\d+)
                replacement: $1:$2
                target_label: __address__
              - action: labelmap
                regex: __meta_kubernetes_pod_label_(.+)
              - source_labels: [__meta_kubernetes_namespace]
                action: replace
                target_label: kubernetes_namespace
              - source_labels: [__meta_kubernetes_pod_name]
                action: replace
                target_label: kubernetes_pod_name
          - job_name: kubernetes-service-endpoints
            kubernetes_sd_configs:
              - role: endpoints
            relabel_configs:
              - action: keep
                regex: true
                source_labels:
                  - __meta_kubernetes_service_annotation_gitlab_com_prometheus_scrape
              - action: replace
                regex: (https?)
                source_labels:
                  - __meta_kubernetes_service_annotation_gitlab_com_prometheus_scheme
                target_label: __scheme__
              - action: replace
                regex: (.+)
                source_labels:
                  - __meta_kubernetes_service_annotation_gitlab_com_prometheus_path
                target_label: __metrics_path__
              - action: replace
                regex: ([^:]+)(?::\d+)?;(\d+)
                replacement: $1:$2
                source_labels:
                  - __address__
                  - __meta_kubernetes_service_annotation_gitlab_com_prometheus_port
                target_label: __address__
              - action: labelmap
                regex: __meta_kubernetes_service_label_(.+)
              - action: replace
                source_labels:
                  - __meta_kubernetes_namespace
                target_label: kubernetes_namespace
              - action: replace
                source_labels:
                  - __meta_kubernetes_service_name
                target_label: kubernetes_name
              - action: replace
                source_labels:
                  - __meta_kubernetes_pod_node_name
                target_label: kubernetes_node
          - job_name: kubernetes-services
            metrics_path: /probe
            params:
              module: [http_2xx]
            kubernetes_sd_configs:
              - role: service
            relabel_configs:
              - source_labels:
                  [
                    __meta_kubernetes_service_annotation_gitlab_com_prometheus_probe,
                  ]
                action: keep
                regex: true
              - source_labels: [__address__]
                target_label: __param_target
              - target_label: __address__
                replacement: blackbox
              - source_labels: [__param_target]
                target_label: instance
              - action: labelmap
                regex: __meta_kubernetes_service_label_(.+)
              - source_labels: [__meta_kubernetes_namespace]
                target_label: kubernetes_namespace
              - source_labels: [__meta_kubernetes_service_name]
                target_label: kubernetes_name

  ## Configuration of Redis
  ## https://docs.gitlab.com/charts/architecture/decisions#redis
  ## https://docs.gitlab.com/charts/installation/deployment.html#redis
  redis:
    install: false
    existingSecret: gitlab-redis-secret
    existingSecretKey: redis-password
    usePasswordFile: true
    cluster:
      enabled: false
    metrics:
      enabled: true

  ## Installation & configuration of stable/prostgresql
  ## See requirements.yaml for current version
  postgresql:
    install: false
    postgresqlDatabase: gitlabhq_production
    image:
      tag: 12.7.0
    usePasswordFile: true
    existingSecret: bogus
    initdbScriptsConfigMap: bogus
    master:
      extraVolumeMounts:
        - name: custom-init-scripts
          mountPath: /docker-entrypoint-preinitdb.d/init_revision.sh
          subPath: init_revision.sh
      podAnnotations:
        postgresql.gitlab/init-revision: "1"
    metrics:
      enabled: true
      ## Optionally define additional custom metrics
      ## ref: https://github.com/wrouesnel/postgres_exporter#adding-new-metrics-via-a-config-file

  ## Installation & configuration charts/registry
  ## https://docs.gitlab.com/charts/architecture/decisions#registry
  ## https://docs.gitlab.com/charts/charts/registry/
  # registry:
  #   enabled: false

  ## Automatic shared secret generation
  ## https://docs.gitlab.com/charts/installation/secrets
  ## https://docs.gitlab.com/charts/charts/shared-secrets.html
  shared-secrets:
    enabled: true

    rbac:
      create: true

    selfsign:
      image:
        # pullPolicy: IfNotPresent
        # pullSecrets: []
        repository: registry.gitlab.com/gitlab-org/build/cng/cfssl-self-sign
        # The digest below comes from a given tag pipeline because they are mirrored to .com,
        # ensuring that the image tag is available from both instances. The digest can be
        # found in the 'sync_images' job.
        #   https://dev.gitlab.org/gitlab/charts/components/images/-/tags
        tag: 1.6.1@sha256:e89392e13b4ef12cd48ba8c30326aacd89a8d0161cb081ac8dfbb77200d5ebac
      keyAlgorithm: "rsa"
      keySize: "4096"
      expiry: "3650d"
      caSubject: "GitLab Helm Chart"

    env: production

    serviceAccount:
      enabled: true
      create: true
      name: # Specify a pre-existing ServiceAccount name

    resources:
      requests:
        cpu: 50m

    securityContext:
      # in debian/alpine based images, this is `nobody:nogroup`
      runAsUser: 65534
      fsGroup: 65534
    tolerations: []
    podLabels: {}
    annotations: {}

  ## Installation & configuration of gitlab/gitlab-runner
  ## See requirements.yaml for current version
  gitlab-runner:
    install: true
    rbac:
      create: true

    runners:
      locked: false
      config: |
        [[runners]]
          [runners.kubernetes]
          image = "ubuntu:18.04"
          {{- if .Values.global.minio.enabled }}
          [runners.cache]
            Type = "s3"
            Path = "gitlab-runner"
            Shared = true
            [runners.cache.s3]
              ServerAddress = {{ include "gitlab-runner.cache-tpl.s3ServerAddress" . }}
              BucketName = "runner-cache"
              BucketLocation = "us-east-1"
              Insecure = false
          {{ end }}
    podAnnotations:
      gitlab.com/prometheus_scrape: "true"
      gitlab.com/prometheus_port: 9252

  ## Installation & configuration of stable/grafana
  ## See requirements.yaml for current version
  ## Controlled by `global.grafana.enabled`
  grafana:
    ## Override and provide "bogus" administation secrets
    ## gitlab/gitlab-grafana provides overrides via shared-secrets
    nameOverride: grafana-app
    admin:
      existingSecret: bogus
    env:
      GF_SECURITY_ADMIN_USER: bogus
      GF_SECURITY_ADMIN_PASSWORD: bogus
    ## This override allows gitlab/gitlab-grafana to completely override the secret
    ##   handling behavior of the upstream chart in combination with the above.
    command: ["sh", "-x", "/tmp/scripts/import-secret.sh"]
    ## The following settings allow Grafana to dynamically create
    ## dashboards and datasources from configmaps. See
    ## https://artifacthub.io/packages/helm/grafana/grafana#sidecar-for-dashboards
    sidecar:
      dashboards:
        enabled: true
        label: gitlab_grafana_dashboard
      datasources:
        enabled: true
        label: gitlab_grafana_datasource
    ## We host Grafana as a sub-url of GitLab
    grafana.ini:
      server:
        serve_from_sub_path: true
        root_url: http://localhost/-/grafana/
      auth:
        login_cookie_name: gitlab_grafana_session
    ## We generate and provide random passwords
    ## NOTE: the Secret & ConfigMap names are hard coded!
    extraSecretMounts:
      - name: initial-password
        mountPath: /tmp/initial
        readOnly: true
        secretName: gitlab-grafana-initial-password
        defaultMode: 400
    extraConfigmapMounts:
      - name: import-secret
        mountPath: /tmp/scripts
        configMap: gitlab-grafana-import-secret
        readOnly: true
    testFramework:
      enabled: false

  ## Settings for individual sub-charts under GitLab
  ## Note: Many of these settings are configurable via globals
  gitlab:
    ## https://docs.gitlab.com/charts/charts/gitlab/toolbox
    toolbox:
      replicas: 1
      antiAffinityLabels:
        matchLabels:
          app: gitaly

    ## https://docs.gitlab.com/charts/charts/gitlab/migrations
    #   migrations:
    #     enabled: false

    ## https://docs.gitlab.com/charts/charts/gitlab/webservice
    #   webservice:
    #     enabled: false

    ## https://docs.gitlab.com/charts/charts/gitlab/sidekiq
    #   sidekiq:
    #     enabled: false

    ## https://docs.gitlab.com/charts/charts/gitlab/gitaly
    #   gitaly:

    ## https://docs.gitlab.com/charts/charts/gitlab/gitlab-shell
    #   gitlab-shell:
    #     enabled: false

    ## https://docs.gitlab.com/charts/charts/gitlab/gitlab-grafana
    #   gitlab-grafana:

    ## https://docs.gitlab.com/charts/charts/gitlab/gitlab-pages
    #   gitlab-pages:

    ## https://docs.gitlab.com/charts/charts/gitlab/kas
    #   kas:

    ## https://docs.gitlab.com/charts/charts/gitlab/praefect
    #   praefect:

fullnameOverride: harbor-core

harbor:
  fullnameOverride: testing123

  expose:
    # Set how to expose the service. Set the type as "ingress", "clusterIP", "nodePort" or "loadBalancer"
    # and fill the information in the corresponding section
    type: ingress

    tls:
      # Enable TLS or not.
      # Delete the "ssl-redirect" annotations in "expose.ingress.annotations" when TLS is disabled and "expose.type" is "ingress"
      # Note: if the "expose.type" is "ingress" and TLS is disabled,
      # the port must be included in the command when pulling/pushing images.
      # Refer to https://github.com/goharbor/harbor/issues/5291 for details.
      enabled: true

      certSource: secret

      secret:
        # The name of secret which contains keys named:
        # "tls.crt" - the certificate
        # "tls.key" - the private key
        secretName: writemycodes-default-certificates
        # The name of secret which contains keys named:
        # "tls.crt" - the certificate
        # "tls.key" - the private key
        # Only needed when the "expose.type" is "ingress".
        notarySecretName: writemycodes-default-certificates

    ingress:
      hosts:
        core: registry.writemy.codes
        notary: notary.writemy.codes

      # set to the type of ingress controller if it has specific requirements.
      # leave as `default` for most ingress controllers.
      # set to `gce` if using the GCE ingress controller
      # set to `ncp` if using the NCP (NSX-T Container Plugin) ingress controller
      controller: default

      className: ''

      annotations:
        # note different ingress controllers may require a different ssl-redirect annotation
        # for Envoy, use ingress.kubernetes.io/force-ssl-redirect: "true" and remove the nginx lines below
        ingress.kubernetes.io/ssl-redirect: "true"
        ingress.kubernetes.io/proxy-body-size: "0"
        nginx.ingress.kubernetes.io/ssl-redirect: "true"
        nginx.ingress.kubernetes.io/proxy-body-size: "0"

      notary:
        # notary ingress-specific annotations
        annotations: {}
        # notary ingress-specific labels
        labels: {}

      harbor:
        # harbor ingress-specific annotations
        annotations: {}
        # harbor ingress-specific labels
        labels: {}

    clusterIP:
      # The name of ClusterIP service
      name: harbor
      # Annotations on the ClusterIP service
      annotations: {}
      ports:
        # The service port Harbor listens on when serving HTTP
        httpPort: 80
        # The service port Harbor listens on when serving HTTPS
        httpsPort: 443
        # The service port Notary listens on. Only needed when notary.enabled
        # is set to true
        notaryPort: 4443

    nodePort:
      # The name of NodePort service
      name: harbor
      ports:
        http:
          # The service port Harbor listens on when serving HTTP
          port: 80
          # The node port Harbor listens on when serving HTTP
          nodePort: 30002
        https:
          # The service port Harbor listens on when serving HTTPS
          port: 443
          # The node port Harbor listens on when serving HTTPS
          nodePort: 30003
        # Only needed when notary.enabled is set to true
        notary:
          # The service port Notary listens on
          port: 4443
          # The node port Notary listens on
          nodePort: 30004

    loadBalancer:
      # The name of LoadBalancer service
      name: harbor
      # Set the IP if the LoadBalancer supports assigning IP
      IP: ""
      ports:
        # The service port Harbor listens on when serving HTTP
        httpPort: 80
        # The service port Harbor listens on when serving HTTPS
        httpsPort: 443
        # The service port Notary listens on. Only needed when notary.enabled
        # is set to true
        notaryPort: 4443
      annotations: {}
      sourceRanges: []

  # The external URL for Harbor core service. It is used to
  # 1) populate the docker/helm commands showed on portal
  # 2) populate the token service URL returned to docker/notary client
  #
  # Format: protocol://domain[:port]. Usually:
  # 1) if "expose.type" is "ingress", the "domain" should be
  # the value of "expose.ingress.hosts.core"
  # 2) if "expose.type" is "clusterIP", the "domain" should be
  # the value of "expose.clusterIP.name"
  # 3) if "expose.type" is "nodePort", the "domain" should be
  # the IP address of k8s node
  #
  # If Harbor is deployed behind the proxy, set it as the URL of proxy
  externalURL: https://registry.writemy.codes

  # The internal TLS used for harbor components secure communicating. In order to enable https
  # in each components tls cert files need to provided in advance.
  internalTLS:
    # If internal TLS enabled
    enabled: false

  ipFamily:
    # ipv6Enabled set to true if ipv6 is enabled in cluster, currently it affected the nginx related component
    ipv6:
      enabled: true
    # ipv4Enabled set to true if ipv4 is enabled in cluster, currently it affected the nginx related component
    ipv4:
      enabled: true

  # The persistence is enabled by default and a default StorageClass
  # is needed in the k8s cluster to provision volumes dynamically.
  # Specify another StorageClass in the "storageClass" or set "existingClaim"
  # if you already have existing persistent volumes to use
  #
  # For storing images and charts, you can also use "azure", "gcs", "s3",
  # "swift" or "oss". Set it in the "imageChartStorage" section
  persistence:
    enabled: false

    # Define which storage backend is used for registry and chartmuseum to store
    # images and charts. Refer to
    # https://github.com/docker/distribution/blob/master/docs/configuration.md#storage
    # for the detail.
    imageChartStorage:
      # Specify whether to disable `redirect` for images and chart storage, for
      # backends which not supported it (such as using minio for `s3` storage type), please disable
      # it. To disable redirects, simply set `disableredirect` to `true` instead.
      # Refer to
      # https://github.com/docker/distribution/blob/master/docs/configuration.md#redirect
      # for the detail.
      disableredirect: false

      # Specify the "caBundleSecretName" if the storage service uses a self-signed certificate.
      # The secret must contain keys named "ca.crt" which will be injected into the trust store
      # of registry's and chartmuseum's containers.
      # caBundleSecretName:

      # Specify the type of storage: "filesystem", "azure", "gcs", "s3", "swift",
      # "oss" and fill the information needed in the corresponding section. The type
      # must be "filesystem" if you want to use persistent volumes for registry
      # and chartmuseum
      type: s3

      filesystem:
        rootdirectory: /storage
        #maxthreads: 100

      s3:
        region: us-east-1
        bucket: <secret:CORE0_SITE1/data/Harbor~S3Bucket>
        accesskey: <secret:CORE0_SITE1/data/Harbor~S3AccessKey>
        secretkey: <secret:CORE0_SITE1/data/Harbor~S3SecretKey>
        regionendpoint: https://s3.mylogin.space

  imagePullPolicy: IfNotPresent

  # Use this set to assign a list of default pullSecrets
  imagePullSecrets:
  #  - name: docker-registry-secret
  #  - name: internal-registry-secret

  # The update strategy for deployments with persistent volumes(jobservice, registry
  # and chartmuseum): "RollingUpdate" or "Recreate"
  # Set it as "Recreate" when "RWM" for volumes isn't supported
  updateStrategy:
    type: RollingUpdate

  # debug, info, warning, error or fatal
  logLevel: warning

  # The initial password of Harbor admin. Change it from portal after launching Harbor
  harborAdminPassword: "Harbor12345"

  # The name of the secret which contains key named "ca.crt". Setting this enables the
  # download link on portal to download the CA certificate when the certificate isn't
  # generated automatically
  caSecretName: ""

  # The secret key used for encryption. Must be a string of 16 chars.
  secretKey: <secret:CORE0_SITE1/data/Harbor~SecretKey>

  # The proxy settings for updating trivy vulnerabilities from the Internet and replicating
  # artifacts from/to the registries that cannot be reached directly
  proxy:
    httpProxy:
    httpsProxy:
    noProxy: 127.0.0.1,localhost,.local,.internal
    components:
      - core
      - jobservice
      - trivy

  # Run the migration job via helm hook
  enableMigrateHelmHook: true

  # The custom ca bundle secret, the secret must contain key named "ca.crt"
  # which will be injected into the trust store for chartmuseum, core, jobservice, registry, trivy components
  # caBundleSecretName: ""

  ## UAA Authentication Options
  # If you're using UAA for authentication behind a self-signed
  # certificate you will need to provide the CA Cert.
  # Set uaaSecretName below to provide a pre-created secret that
  # contains a base64 encoded CA Certificate named `ca.crt`.
  # uaaSecretName:

  # If service exposed via "ingress", the Nginx will not be used
  nginx:
    image:
      repository: goharbor/nginx-photon

    # set the service account to be used, default if left empty
    serviceAccountName: ""

    # mount the service account token
    automountServiceAccountToken: false

    replicas: 1

    revisionHistoryLimit: 10

    # resources:
    #  requests:
    #    memory: 256Mi
    #    cpu: 100m

    nodeSelector: {}

    tolerations: []

    affinity: {}

    ## Additional deployment annotations
    podAnnotations: {}

    ## The priority class to run the pod as
    priorityClassName:

  portal:
    image:
      repository: goharbor/harbor-portal

    # set the service account to be used, default if left empty
    serviceAccountName: ""

    # mount the service account token
    automountServiceAccountToken: false

    replicas: 1

    revisionHistoryLimit: 10

    # resources:
    #  requests:
    #    memory: 256Mi
    #    cpu: 100m

    nodeSelector: {}

    tolerations: []

    affinity: {}

    ## Additional deployment annotations
    podAnnotations: {}

    ## The priority class to run the pod as
    priorityClassName:

  core:
    image:
      repository: goharbor/harbor-core

    # set the service account to be used, default if left empty
    serviceAccountName: ""
    # mount the service account token

    automountServiceAccountToken: false

    replicas: 1

    revisionHistoryLimit: 10

    ## Startup probe values
    startupProbe:
      enabled: true
      initialDelaySeconds: 10

    # resources:
    #  requests:
    #    memory: 256Mi
    #    cpu: 100m

    nodeSelector: {}

    tolerations: []

    affinity: {}

    ## Additional deployment annotations
    podAnnotations: {}

    # Secret is used when core server communicates with other components.
    # If a secret key is not specified, Helm will generate one.
    # Must be a string of 16 chars.
    secret: <secret:CORE0_SITE1/data/Harbor~CoreSecret>

    # Fill the name of a kubernetes secret if you want to use your own
    # TLS certificate and private key for token encryption/decryption.
    # The secret must contain keys named:
    # "tls.crt" - the certificate
    # "tls.key" - the private key
    # The default key pair will be used if it isn't set
    secretName: ''

    # The XSRF key. Will be generated automatically if it isn't specified
    xsrfKey: <secret:CORE0_SITE1/data/Harbor~CSRF_KEY>

    ## The priority class to run the pod as
    priorityClassName:

    # The time duration for async update artifact pull_time and repository
    # pull_count, the unit is second. Will be 10 seconds if it isn't set.
    # eg. artifactPullAsyncFlushDuration: 10
    artifactPullAsyncFlushDuration:

  jobservice:
    image:
      repository: goharbor/harbor-jobservice

    replicas: 1

    revisionHistoryLimit: 10

    # set the service account to be used, default if left empty
    serviceAccountName: ""

    # mount the service account token
    automountServiceAccountToken: false

    maxJobWorkers: 10

    # The logger for jobs: "file", "database" or "stdout"
    jobLoggers:
      #- file
      # - database
      - stdout

    # The jobLogger sweeper duration (ignored if `jobLogger` is `stdout`)
    loggerSweeperDuration: 14 #days

    # resources:
    #   requests:
    #     memory: 256Mi
    #     cpu: 100m

    nodeSelector: {}

    tolerations: []

    affinity: {}

    ## Additional deployment annotations
    podAnnotations: {}

    # Secret is used when job service communicates with other components.
    # If a secret key is not specified, Helm will generate one.
    # Must be a string of 16 chars.
    secret: <secret:CORE0_SITE1/data/Harbor~JobServiceSecret>

    ## The priority class to run the pod as
    priorityClassName:

  registry:
    # set the service account to be used, default if left empty
    serviceAccountName: ""

    # mount the service account token
    automountServiceAccountToken: false
    registry:
      image:
        repository: goharbor/registry-photon

      # resources:
      #  requests:
      #    memory: 256Mi
      #    cpu: 100m

    controller:
      image:
        repository: goharbor/harbor-registryctl

      # resources:
      #  requests:
      #    memory: 256Mi
      #    cpu: 100m

    replicas: 3

    revisionHistoryLimit: 10

    nodeSelector: {}

    tolerations: []

    affinity: {}

    ## Additional deployment annotations
    podAnnotations: {}

    ## The priority class to run the pod as
    priorityClassName:

    # Secret is used to secure the upload state from client
    # and registry storage backend.
    # See: https://github.com/docker/distribution/blob/master/docs/configuration.md#http
    # If a secret key is not specified, Helm will generate one.
    # Must be a string of 16 chars.
    secret: <secret:CORE0_SITE1/data/Harbor~RegistrySecret>

    # If true, the registry returns relative URLs in Location headers. The client is responsible for resolving the correct URL.
    relativeurls: false

    credentials:
      username: 'harbor_registry_user'
      password: 'harbor_registry_password'
      # Login and password in htpasswd string format. Excludes `registry.credentials.username`  and `registry.credentials.password`. May come in handy when integrating with tools like argocd or flux. This allows the same line to be generated each time the template is rendered, instead of the `htpasswd` function from helm, which generates different lines each time because of the salt.
      # htpasswdString: $apr1$XLefHzeG$Xl4.s00sMSCCcMyJljSZb0 # example string

    middleware:
      enabled: false
      type: cloudFront
      cloudFront:
        baseurl: example.cloudfront.net
        keypairid: KEYPAIRID
        duration: 3000s
        ipfilteredby: none
        # The secret key that should be present is CLOUDFRONT_KEY_DATA, which should be the encoded private key
        # that allows access to CloudFront
        privateKeySecret: "my-secret"

    # enable purge _upload directories
    upload_purging:
      enabled: true
      # remove files in _upload directories which exist for a period of time, default is one week.
      age: 168h
      # the interval of the purge operations
      interval: 24h
      dryrun: false

  chartmuseum:
    enabled: true

    # set the service account to be used, default if left empty
    serviceAccountName: ""

    # mount the service account token
    automountServiceAccountToken: false

    # Harbor defaults ChartMuseum to returning relative urls, if you want using absolute url you should enable it by change the following value to 'true'
    absoluteUrl: false

    image:
      repository: goharbor/chartmuseum-photon

    replicas: 1

    revisionHistoryLimit: 10

    # resources:
    #  requests:
    #    memory: 256Mi
    #    cpu: 100m

    nodeSelector: {}

    tolerations: []

    affinity: {}

    ## Additional deployment annotations
    podAnnotations: {}

    ## The priority class to run the pod as
    priorityClassName:

    ## limit the number of parallel indexers
    indexLimit: 0

  trivy:
    # enabled the flag to enable Trivy scanner
    enabled: false

    image:
      # repository the repository for Trivy adapter image
      repository: goharbor/trivy-adapter-photon
      # tag the tag for Trivy adapter image

    # set the service account to be used, default if left empty
    serviceAccountName: ""

    # mount the service account token
    automountServiceAccountToken: false

    # replicas the number of Pod replicas
    replicas: 1

    # debugMode the flag to enable Trivy debug mode with more verbose scanning log
    debugMode: false

    # vulnType a comma-separated list of vulnerability types. Possible values are `os` and `library`.
    vulnType: "os,library"

    # severity a comma-separated list of severities to be checked
    severity: "UNKNOWN,LOW,MEDIUM,HIGH,CRITICAL"

    # ignoreUnfixed the flag to display only fixed vulnerabilities
    ignoreUnfixed: false

    # insecure the flag to skip verifying registry certificate
    insecure: false

    # gitHubToken the GitHub access token to download Trivy DB
    #
    # Trivy DB contains vulnerability information from NVD, Red Hat, and many other upstream vulnerability databases.
    # It is downloaded by Trivy from the GitHub release page https://github.com/aquasecurity/trivy-db/releases and cached
    # in the local file system (`/home/scanner/.cache/trivy/db/trivy.db`). In addition, the database contains the update
    # timestamp so Trivy can detect whether it should download a newer version from the Internet or use the cached one.
    # Currently, the database is updated every 12 hours and published as a new release to GitHub.
    #
    # Anonymous downloads from GitHub are subject to the limit of 60 requests per hour. Normally such rate limit is enough
    # for production operations. If, for any reason, it's not enough, you could increase the rate limit to 5000
    # requests per hour by specifying the GitHub access token. For more details on GitHub rate limiting please consult
    # https://developer.github.com/v3/#rate-limiting
    #
    # You can create a GitHub token by following the instructions in
    # https://help.github.com/en/github/authenticating-to-github/creating-a-personal-access-token-for-the-command-line
    gitHubToken: ""


    # skipUpdate the flag to disable Trivy DB downloads from GitHub
    #
    # You might want to set the value of this flag to `true` in test or CI/CD environments to avoid GitHub rate limiting issues.
    # If the value is set to `true` you have to manually download the `trivy.db` file and mount it in the
    # `/home/scanner/.cache/trivy/db/trivy.db` path.
    skipUpdate: false


    # The offlineScan option prevents Trivy from sending API requests to identify dependencies.
    #
    # Scanning JAR files and pom.xml may require Internet access for better detection, but this option tries to avoid it.
    # For example, the offline mode will not try to resolve transitive dependencies in pom.xml when the dependency doesn't
    # exist in the local repositories. It means a number of detected vulnerabilities might be fewer in offline mode.
    # It would work if all the dependencies are in local.
    # This option doesnt affect DB download. You need to specify skipUpdate as well as offlineScan in an air-gapped environment.
    offlineScan: false
    # The duration to wait for scan completion

    timeout: 5m0s

    resources:
      requests:
        cpu: 200m
        memory: 512Mi

      limits:
        cpu: 1
        memory: 1Gi

    nodeSelector: {}

    tolerations: []

    affinity: {}

    ## Additional deployment annotations
    podAnnotations: {}

    ## The priority class to run the pod as
    priorityClassName:

  notary:
    enabled: false

    server:
      # set the service account to be used, default if left empty
      serviceAccountName: ""

      # mount the service account token
      automountServiceAccountToken: false

      image:
        repository: goharbor/notary-server-photon

      replicas: 1

      # resources:
      #  requests:
      #    memory: 256Mi
      #    cpu: 100m

      nodeSelector: {}

      tolerations: []

      affinity: {}

      ## Additional deployment annotations
      podAnnotations: {}

      ## The priority class to run the pod as
      priorityClassName:

    signer:
      # set the service account to be used, default if left empty
      serviceAccountName: ""

      # mount the service account token
      automountServiceAccountToken: false

      image:
        repository: goharbor/notary-signer-photon

      replicas: 1

      # resources:
      #  requests:
      #    memory: 256Mi
      #    cpu: 100m

      nodeSelector: {}

      tolerations: []

      affinity: {}

      ## Additional deployment annotations
      podAnnotations: {}

      ## The priority class to run the pod as
      priorityClassName:

    # Fill the name of a kubernetes secret if you want to use your own
    # TLS certificate authority, certificate and private key for notary
    # communications.
    # The secret must contain keys named ca.crt, tls.crt and tls.key that
    # contain the CA, certificate and private key.
    # They will be generated if not set.
    secretName: ""

  database:
    # if external database is used, set "type" to "external"
    # and fill the connection informations in "external" section
    type: external

    external:
      host: psql.service.dc1.kjdev

      port: '5432'
      
      username: <secret:CORE0_SITE1/data/Harbor~DatabaseUsername>
      password: <secret:CORE0_SITE1/data/Harbor~DatabasePassword>
      
      coreDatabase: <secret:CORE0_SITE1/data/Harbor~DatabaseDatabase>
      
      notaryServerDatabase: "notary_server"
      
      notarySignerDatabase: "notary_signer"
      
      # "disable" - No SSL
      # "require" - Always SSL (skip verification)
      # "verify-ca" - Always SSL (verify that the certificate presented by the
      # server was signed by a trusted CA)
      # "verify-full" - Always SSL (verify that the certification presented by the
      # server was signed by a trusted CA and the server host name matches the one
      # in the certificate)
      sslmode: "disable"
    
    # The maximum number of connections in the idle connection pool per pod (core+exporter).
    # If it <=0, no idle connections are retained.
    maxIdleConns: 100
    
    # The maximum number of open connections to the database per pod (core+exporter).
    # If it <= 0, then there is no limit on the number of open connections.
    # Note: the default number of connections is 1024 for postgre of harbor.
    maxOpenConns: 900

    ## Additional deployment annotations
    podAnnotations: {}

  redis:
    # if external Redis is used, set "type" to "external"
    # and fill the connection informations in "external" section
    type: external

    external:
      # support redis, redis+sentinel
      # addr for redis: <host_redis>:<port_redis>
      # addr for redis+sentinel: <host_sentinel1>:<port_sentinel1>,<host_sentinel2>:<port_sentinel2>,<host_sentinel3>:<port_sentinel3>
      addr: 10.1.1.68:6379
      # The name of the set of Redis instances to monitor, it must be set to support redis+sentinel
      sentinelMasterSet: ""

      # The "coreDatabaseIndex" must be "0" as the library Harbor
      # used doesn't support configuring it
      coreDatabaseIndex: '0'
      jobserviceDatabaseIndex: '7'
      registryDatabaseIndex: '8'
      chartmuseumDatabaseIndex: '9'
      trivyAdapterIndex: '14'

      password: ""

    ## Additional deployment annotations
    podAnnotations: {}

  exporter:
    replicas: 1

    revisionHistoryLimit: 10

  # resources:
  #  requests:
  #    memory: 256Mi
  #    cpu: 100m

    podAnnotations: {}

    serviceAccountName: ""

    # mount the service account token
    automountServiceAccountToken: false

    image:
      repository: goharbor/harbor-exporter

    nodeSelector: {}

    tolerations: []

    affinity: {}

    cacheDuration: 23

    cacheCleanInterval: 14400

    ## The priority class to run the pod as
    priorityClassName:

  metrics:
    enabled: false

    core:
      path: /metrics
      port: 8001

    registry:
      path: /metrics
      port: 8001

    jobservice:
      path: /metrics
      port: 8001

    exporter:
      path: /metrics
      port: 8001

    ## Create prometheus serviceMonitor to scrape harbor metrics.
    ## This requires the monitoring.coreos.com/v1 CRD. Please see
    ## https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/user-guides/getting-started.md
    ##
    serviceMonitor:
      enabled: false
      additionalLabels: {}
      # Scrape interval. If not set, the Prometheus default scrape interval is used.
      interval: ""
      # Metric relabel configs to apply to samples before ingestion.
      metricRelabelings: []
        # - action: keep
        #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'
        #   sourceLabels: [__name__]
      # Relabel configs to apply to samples before ingestion.
      relabelings: []
        # - sourceLabels: [__meta_kubernetes_pod_node_name]
        #   separator: ;
        #   regex: ^(.*)$
        #   targetLabel: nodename
        #   replacement: $1
        #   action: replace

  trace:
    enabled: false
    # trace provider: jaeger or otel
    # jaeger should be 1.26+
    provider: otel
    # set sample_rate to 1 if you wanna sampling 100% of trace data; set 0.5 if you wanna sampling 50% of trace data, and so forth
    sample_rate: 0.025
    # namespace used to differentiate different harbor services
    # namespace:
    # attributes is a key value dict contains user defined attributes used to initialize trace provider
    # attributes:
    #   application: harbor

    otel:
      endpoint: hostname:4318
      url_path: /v1/traces
      compression: true
      insecure: true
      timeout: 10s
