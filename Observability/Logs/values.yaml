loki:
  # -- Overrides the version used to determine compatibility of resources with the target Kubernetes cluster.
  # This is useful when using `helm template`, because then helm will use the client version of kubectl as the Kubernetes version,
  # which may or may not match your cluster's server version. Example: 'v1.24.4'. Set to null to use the version that helm
  # devises.
  kubeVersionOverride: null

  global:
    image:
      # -- Overrides the Docker registry globally for all images
      registry: null
    
    # -- Overrides the priorityClassName for all pods
    priorityClassName: null

    # -- configures cluster domain ("cluster.local" by default)
    clusterDomain: "cluster.local"
    
    # -- configures DNS service name
    dnsService: "kube-dns"
    
    # -- configures DNS service namespace
    dnsNamespace: "kube-system"
  
  # -- Overrides the chart's computed fullname
  fullnameOverride: 'loki-core'
  
  # -- Overrides the chart's cluster label
  clusterLabelOverride: null
  
  # -- Image pull secrets for Docker images
  imagePullSecrets: []
  # -- Deployment mode lets you specify how to deploy Loki.

  # There are 3 options:
  # - SingleBinary: Loki is deployed as a single binary, useful for small installs typically without HA, up to a few tens of GB/day.

  # - SimpleScalable: Loki is deployed as 3 targets: read, write, and backend. Useful for medium installs easier to manage than distributed, up to a about 1TB/day.

  # - Distributed: Loki is deployed as individual microservices. The most complicated but most capable, useful for large installs, typically over 1TB/day.
  # There are also 2 additional modes used for migrating between deployment modes:
  # - SingleBinary<->SimpleScalable: Migrate from SingleBinary to SimpleScalable (or vice versa)
  # - SimpleScalable<->Distributed: Migrate from SimpleScalable to Distributed (or vice versa)
  # Note: SimpleScalable and Distributed REQUIRE the use of object storage.
  deploymentMode: Distributed

  backend:
    replicas: 0
  read:
    replicas: 0
  write:
    replicas: 0

  singleBinary:
    replicas: 0


  ######################################################################################################################
  #
  # Base Loki Configs including kubernetes configurations and configurations for Loki itself,
  # see below for more specifics on Loki's configuration.
  #
  ######################################################################################################################

  # -- Configuration for running Loki
  # @default -- See values.yaml
  loki:
    # Configures the readiness probe for all of the Loki pods
    readinessProbe:
      httpGet:
        path: /ready
        port: http-metrics
      initialDelaySeconds: 30
      timeoutSeconds: 1

    image:
      # -- The Docker registry
      registry: docker.io

      # -- Docker image repository
      repository: grafana/loki

      # -- Docker image pull policy
      pullPolicy: IfNotPresent

    # -- Common annotations for all deployments/StatefulSets
    annotations: {}

    # -- Common annotations for all pods
    podAnnotations: {}

    # -- Common labels for all pods
    podLabels: {}

    # -- Common annotations for all services
    serviceAnnotations: {}

    # -- Common labels for all services
    serviceLabels: {}

    # -- The number of old ReplicaSets to retain to allow rollback
    revisionHistoryLimit: 10

    # -- The SecurityContext for Loki pods
    podSecurityContext:
      fsGroup: 10001
      runAsGroup: 10001
      runAsNonRoot: true
      runAsUser: 10001

    # -- The SecurityContext for Loki containers
    containerSecurityContext:
      readOnlyRootFilesystem: true
      capabilities:
        drop:
          - ALL
      allowPrivilegeEscalation: false

    # -- Should enableServiceLinks be enabled. Default to enable
    enableServiceLinks: true
    ######################################################################################################################
    #
    # Loki Configuration
    #
    # There are several ways to pass configuration to Loki, listing them here in order of our preference for how
    # you should use this chart.
    # 1. Use the templated value of loki.config below and the corresponding override sections which follow.
    #    This allows us to set a lot of important Loki configurations and defaults and also allows us to maintain them
    #    over time as Loki changes and evolves.
    # 2. Use the loki.structuredConfig section.
    #    This will completely override the templated value of loki.config, so you MUST provide the entire Loki config
    #    including any configuration that we set in loki.config unless you explicitly are trying to change one of those
    #    values and are not able to do so with the templated sections.
    #    If you choose this approach the burden is on you to maintain any changes we make to the templated config.
    # 3. Use an existing secret or configmap to provide the configuration.
    #    This option is mostly provided for folks who have external processes which provide or modify the configuration.
    #    When using this option you can specify a different name for loki.generatedConfigObjectName and configObjectName
    #    if you have a process which takes the generated config and modifies it, or you can stop the chart from generating
    #    a config entirely by setting loki.generatedConfigObjectName to
    #
    ######################################################################################################################

    # -- Defines what kind of object stores the configuration, a ConfigMap or a Secret.
    # In order to move sensitive information (such as credentials) from the ConfigMap/Secret to a more secure location (e.g. vault), it is possible to use [environment variables in the configuration](https://grafana.com/docs/loki/latest/configuration/#use-environment-variables-in-the-configuration).
    # Such environment variables can be then stored in a separate Secret and injected via the global.extraEnvFrom value. For details about environment injection from a Secret please see [Secrets](https://kubernetes.io/docs/concepts/configuration/secret/#use-case-as-container-environment-variables).
    configStorageType: ConfigMap
    # -- The name of the object which Loki will mount as a volume containing the config.
    # If the configStorageType is Secret, this will be the name of the Secret, if it is ConfigMap, this will be the name of the ConfigMap.
    # The value will be passed through tpl.
    configObjectName: '{{ include "loki.name" . }}'
    # -- The name of the Secret or ConfigMap that will be created by this chart.
    # If empty, no configmap or secret will be created.
    # The value will be passed through tpl.
    generatedConfigObjectName: '{{ include "loki.name" . }}'

    # Should authentication be enabled
    auth_enabled: true

    # -- memberlist configuration (overrides embedded default)
    memberlistConfig: {}

    # -- Extra memberlist configuration
    extraMemberlistConfig: {}

    # -- Tenants list to be created on nginx htpasswd file, with name and password keys
    tenants: []

    # -- Check https://grafana.com/docs/loki/latest/configuration/#server for more info on the server configuration.
    server:
      http_listen_port: 3100
      grpc_listen_port: 9095
      http_server_read_timeout: 600s
      http_server_write_timeout: 600s

    # -- Limits config
    limits_config:
      reject_old_samples: true
      reject_old_samples_max_age: 168h
      max_cache_freshness_per_query: 10m
      split_queries_by_interval: 15m
      query_timeout: 300s
      allow_structured_metadata: true
      volume_enabled: true


    # -- Provides a reloadable runtime configuration file for some specific configuration
    runtimeConfig: {}

    # -- Check https://grafana.com/docs/loki/latest/configuration/#common_config for more info on how to provide a common configuration
    commonConfig:
      path_prefix: /var/loki
      replication_factor: 3
      compactor_address: '{{ include "loki.compactorAddress" . }}'

    # -- Storage config. Providing this will automatically populate all necessary storage configs in the templated config.
    storage:
      # Loki requires a bucket for chunks and the ruler. GEL requires a third bucket for the admin API.
      # Please provide these values if you are using object storage.
      bucketNames:
        chunks: 59c3f49a-43d4-4d95-80b1-5155f99f2094
        ruler: 403e9f61-6d18-45b0-827d-cec519b5c581
        admin: da6355e0-7148-42bc-8628-18a5eca97e04
      type: s3
      s3:
        s3: ${S3_URI}
        endpoint: ${S3_ENDPOINT}
        region: 'us-east-1'
        secretAccessKey: ${S3_SECRET_ACCESS_KEY}
        accessKeyId: ${S3_ACCESS_KEY}
        signatureVersion: null
        s3ForcePathStyle: true
        insecure: false
        http_config: {}
        # -- Check https://grafana.com/docs/loki/latest/configure/#s3_storage_config for more info on how to provide a backoff_config
        backoff_config: {}
        disable_dualstack: false

    # -- Configure memcached as an external cache for chunk and results cache. Disabled by default
    # must enable and specify a host for each cache you would like to use.
    memcached:
      chunk_cache:
        enabled: false
        host: ""
        service: "memcached-client"
        batch_size: 256
        parallelism: 10
      results_cache:
        enabled: false
        host: ""
        service: "memcached-client"
        timeout: "500ms"
        default_validity: "12h"
    # -- Check https://grafana.com/docs/loki/latest/configuration/#schema_config for more info on how to configure schemas
    schemaConfig:
      configs:
        - from: 2024-04-01
          store: tsdb
          object_store: s3
          schema: v13
          index:
            prefix: loki_index_
            period: 24h
    # -- a real Loki install requires a proper schemaConfig defined above this, however for testing or playing around
    # you can enable useTestSchema
    useTestSchema: false

    testSchemaConfig:
      configs:
        - from: 2024-04-01
          store: tsdb
          object_store: '{{ include "loki.testSchemaObjectStore" . }}'
          schema: v13
          index:
            prefix: index_
            period: 24h

    # -- Check https://grafana.com/docs/loki/latest/configuration/#ruler for more info on configuring ruler
    rulerConfig:
      wal:
        dir: /var/loki/ruler-wal

    # -- Structured loki configuration, takes precedence over `loki.config`, `loki.schemaConfig`, `loki.storageConfig`
    structuredConfig: {}

    # -- Additional query scheduler config
    query_scheduler: {}

    # -- Additional storage config
    storage_config:
      boltdb_shipper:
        index_gateway_client:
          server_address: '{{ include "loki.indexGatewayAddress" . }}'
      tsdb_shipper:
        index_gateway_client:
          server_address: '{{ include "loki.indexGatewayAddress" . }}'
      bloom_shipper:
        working_directory: /var/loki/data/bloomshipper
      hedging:
        at: "250ms"
        max_per_second: 20
        up_to: 3

    # --  Optional compactor configuration
    compactor: {}
    
    # --  Optional pattern ingester configuration
    pattern_ingester:
      enabled: true
    
    # --  Optional analytics configuration
    analytics: {}
    
    # --  Optional querier configuration
    query_range: {}
    
    # --  Optional querier configuration
    querier:
      max_concurrent: 4
    
    # --  Optional ingester configuration
    ingester:
      chunk_encoding: snappy
    
    # --  Optional index gateway configuration
    index_gateway:
      mode: simple
    
    frontend:
      scheduler_address: '{{ include "loki.querySchedulerAddress" . }}'
      tail_proxy_url: '{{ include "loki.querierAddress" . }}'
    
    frontend_worker:
      scheduler_address: '{{ include "loki.querySchedulerAddress" . }}'
    
    # -- Optional distributor configuration
    distributor: {}

    # -- Enable tracing
    tracing:
      enabled: false

    bloom_build:
      enabled: false
      builder:
        planner_address: '{{ include "loki.bloomPlannerAddress" . }}'
    bloom_gateway:
      enabled: false
      client:
        addresses: '{{ include "loki.bloomGatewayAddresses" . }}'

  ######################################################################################################################
  #
  # Enterprise Loki Configs
  #
  ######################################################################################################################

  # -- Configuration for running Enterprise Loki
  enterprise:
    # Enable enterprise features, license must be provided
    enabled: false

  ######################################################################################################################
  #
  # Chart Testing
  #
  ######################################################################################################################

  # -- Section for configuring optional Helm test
  test:
    enabled: true
    # -- Used to directly query the metrics endpoint of the canary for testing, this approach avoids needing prometheus for testing.
    # This in a newer approach to using prometheusAddress such that tests do not have a dependency on prometheus
    canaryServiceAddress: "http://loki-canary:3500/metrics"
    # -- Address of the prometheus server to query for the test. This overrides any value set for canaryServiceAddress.
    # This is kept for backward compatibility and may be removed in future releases. Previous value was 'http://prometheus:9090'
    prometheusAddress: ""
    # -- Number of times to retry the test before failing
    timeout: 1m
    # -- Additional labels for the test pods
    labels: {}
    # -- Additional annotations for test pods
    annotations: {}
    # -- Image to use for loki canary
    image:
      # -- The Docker registry
      registry: docker.io
      # -- Docker image repository
      repository: grafana/loki-helm-test
      # -- Overrides the image tag whose default is the chart's appVersion
      tag: "ewelch-distributed-helm-chart-17db5ee"
      # -- Overrides the image tag with an image digest
      digest: null
      # -- Docker image pull policy
      pullPolicy: IfNotPresent
  # The Loki canary pushes logs to and queries from this loki installation to test
  # that it's working correctly
  lokiCanary:
    enabled: true
    # -- If true, the canary will send directly to Loki via the address configured for verification --
    # -- If false, it will write to stdout and an Agent will be needed to scrape and send the logs --
    push: true
    # -- The name of the label to look for at loki when doing the checks.
    labelname: pod
    # -- Additional annotations for the `loki-canary` Daemonset
    annotations: {}
    # -- Additional labels for each `loki-canary` pod
    podLabels: {}
    service:
      # -- Annotations for loki-canary Service
      annotations: {}
      # -- Additional labels for loki-canary Service
      labels: {}
    # -- Additional CLI arguments for the `loki-canary' command
    extraArgs: []
    # -- Environment variables to add to the canary pods
    extraEnv: []
    # -- Environment variables from secrets or configmaps to add to the canary pods
    extraEnvFrom: []
    # -- Volume mounts to add to the canary pods
    extraVolumeMounts: []
    # -- Volumes to add to the canary pods
    extraVolumes: []
    # -- Resource requests and limits for the canary
    resources: {}
    # -- DNS config for canary pods
    dnsConfig: {}
    # -- Node selector for canary pods
    nodeSelector: {}
    # -- Tolerations for canary pods
    tolerations: []
    # -- The name of the PriorityClass for loki-canary pods
    priorityClassName: null
    # -- Image to use for loki canary
    image:
      # -- The Docker registry
      registry: docker.io
      # -- Docker image repository
      repository: grafana/loki-canary
      # -- Overrides the image tag whose default is the chart's appVersion
      tag: null
      # -- Overrides the image tag with an image digest
      digest: null
      # -- Docker image pull policy
      pullPolicy: IfNotPresent
    # -- Update strategy for the `loki-canary` Daemonset pods
    updateStrategy:
      type: RollingUpdate
      rollingUpdate:
        maxUnavailable: 1

  ######################################################################################################################
  #
  # Service Accounts and Kubernetes RBAC
  #
  ######################################################################################################################
  serviceAccount:
    # -- Specifies whether a ServiceAccount should be created
    create: true
    # -- The name of the ServiceAccount to use.
    # If not set and create is true, a name is generated using the fullname template
    name: null
    # -- Image pull secrets for the service account
    imagePullSecrets: []
    # -- Annotations for the service account
    annotations: {}
    # -- Labels for the service account
    labels: {}
    # -- Set this toggle to false to opt out of automounting API credentials for the service account
    automountServiceAccountToken: true

  # RBAC configuration
  rbac:
    # -- If pspEnabled true, a PodSecurityPolicy is created for K8s that use psp.
    pspEnabled: false
    # -- For OpenShift set pspEnabled to 'false' and sccEnabled to 'true' to use the SecurityContextConstraints.
    sccEnabled: false
    # -- Specify PSP annotations
    # Ref: https://kubernetes.io/docs/reference/access-authn-authz/psp-to-pod-security-standards/#podsecuritypolicy-annotations
    pspAnnotations: {}
    # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'
    # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'
    # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'
    # -- Whether to install RBAC in the namespace only or cluster-wide. Useful if you want to watch ConfigMap globally.
    namespaced: false

  ######################################################################################################################
  #
  # Network Policy configuration
  #
  ######################################################################################################################
  networkPolicy:
    # -- Specifies whether Network Policies should be created
    enabled: false
    # -- Specifies whether the policies created will be standard Network Policies (flavor: kubernetes)
    # or Cilium Network Policies (flavor: cilium)
    flavor: kubernetes

    metrics:
      # -- Specifies the Pods which are allowed to access the metrics port.
      # As this is cross-namespace communication, you also need the namespaceSelector.
      podSelector: {}

      # -- Specifies the namespaces which are allowed to access the metrics port
      namespaceSelector: {}

      # -- Specifies specific network CIDRs which are allowed to access the metrics port.
      # In case you use namespaceSelector, you also have to specify your kubelet networks here.
      # The metrics ports are also used for probes.
      cidrs: []

    ingress:
      # -- Specifies the Pods which are allowed to access the http port.
      # As this is cross-namespace communication, you also need the namespaceSelector.
      podSelector: {}

      # -- Specifies the namespaces which are allowed to access the http port
      namespaceSelector: {}

    alertmanager:
      # -- Specify the alertmanager port used for alerting
      port: 9093

      # -- Specifies the alertmanager Pods.
      # As this is cross-namespace communication, you also need the namespaceSelector.
      podSelector: {}

      # -- Specifies the namespace the alertmanager is running in
      namespaceSelector: {}

    externalStorage:
      # -- Specify the port used for external storage, e.g. AWS S3
      ports: []

      # -- Specifies specific network CIDRs you want to limit access to
      cidrs: []

    discovery:
      # -- (int) Specify the port used for discovery
      port: null

      # -- Specifies the Pods labels used for discovery.
      # As this is cross-namespace communication, you also need the namespaceSelector.
      podSelector: {}

      # -- Specifies the namespace the discovery Pods are running in
      namespaceSelector: {}

    egressWorld:
      # -- Enable additional cilium egress rules to external world for write, read and backend.
      enabled: false

    egressKubeApiserver:
      # -- Enable additional cilium egress rules to kube-apiserver for backend.
      enabled: false

  ######################################################################################################################
  #
  # Global memberlist configuration
  #
  ######################################################################################################################

  # Configuration for the memberlist service
  memberlist:
    service:
      publishNotReadyAddresses: false
      annotations: {}

  ######################################################################################################################
  #
  # adminAPI configuration, enterprise only.
  #
  ######################################################################################################################

  # -- Configuration for the `admin-api` target
  adminApi:
    # -- Define the amount of instances
    replicas: 1

  ######################################################################################################################
  #
  # Gateway and Ingress
  #
  # By default this chart will deploy a Nginx container to act as a gateway which handles routing of traffic
  # and can also do auth.
  #
  # If you would prefer you can optionally disable this and enable using k8s ingress to do the incoming routing.
  #
  ######################################################################################################################

  # Configuration for the gateway
  gateway:
    # -- Specifies whether the gateway should be enabled
    enabled: false

  # -- Ingress configuration Use either this ingress or the gateway, but not both at once.
  # If you enable this, make sure to disable the gateway.
  # You'll need to supply authn configuration for your ingress controller.
  ingress:
    enabled: false
    ingressClassName: ""
    annotations: {}
    #    nginx.ingress.kubernetes.io/auth-type: basic
    #    nginx.ingress.kubernetes.io/auth-secret: loki-distributed-basic-auth
    #    nginx.ingress.kubernetes.io/auth-secret-type: auth-map
    #    nginx.ingress.kubernetes.io/configuration-snippet: |
    #      proxy_set_header X-Scope-OrgID $remote_user;
    labels: {}
    #    blackbox.monitoring.exclude: "true"
    paths:
      # -- Paths that are exposed by Loki Distributor.
      # If deployment mode is Distributed, the requests are forwarded to the service: `{{"loki.distributorFullname"}}`.
      # If deployment mode is SimpleScalable, the requests are forwarded to write k8s service: `{{"loki.writeFullname"}}`.
      # If deployment mode is SingleBinary, the requests are forwarded to the central/single k8s service: `{{"loki.singleBinaryFullname"}}`
      distributor:
        - /api/prom/push
        - /loki/api/v1/push
        - /otlp/v1/logs
      # -- Paths that are exposed by Loki Query Frontend.
      # If deployment mode is Distributed, the requests are forwarded to the service: `{{"loki.queryFrontendFullname"}}`.
      # If deployment mode is SimpleScalable, the requests are forwarded to write k8s service: `{{"loki.readFullname"}}`.
      # If deployment mode is SingleBinary, the requests are forwarded to the central/single k8s service: `{{"loki.singleBinaryFullname"}}`
      queryFrontend:
        - /api/prom/query
        # this path covers labels and labelValues endpoints
        - /api/prom/label
        - /api/prom/series
        - /api/prom/tail
        - /loki/api/v1/query
        - /loki/api/v1/query_range
        - /loki/api/v1/tail
        # this path covers labels and labelValues endpoints
        - /loki/api/v1/label
        - /loki/api/v1/labels
        - /loki/api/v1/series
        - /loki/api/v1/index/stats
        - /loki/api/v1/index/volume
        - /loki/api/v1/index/volume_range
        - /loki/api/v1/format_query
        - /loki/api/v1/detected_field
        - /loki/api/v1/detected_fields
        - /loki/api/v1/detected_labels
        - /loki/api/v1/patterns
      # -- Paths that are exposed by Loki Ruler.
      # If deployment mode is Distributed, the requests are forwarded to the service: `{{"loki.rulerFullname"}}`.
      # If deployment mode is SimpleScalable, the requests are forwarded to k8s service: `{{"loki.backendFullname"}}`.
      # If deployment mode is SimpleScalable but `read.legacyReadTarget` is `true`, the requests are forwarded to k8s service: `{{"loki.readFullname"}}`.
      # If deployment mode is SingleBinary, the requests are forwarded to the central/single k8s service: `{{"loki.singleBinaryFullname"}}`
      ruler:
        - /api/prom/rules
        - /api/prom/api/v1/rules
        - /api/prom/api/v1/alerts
        - /loki/api/v1/rules
        - /prometheus/api/v1/rules
        - /prometheus/api/v1/alerts
    # -- Hosts configuration for the ingress, passed through the `tpl` function to allow templating
    hosts:
      - loki.example.com
    # -- TLS configuration for the ingress. Hosts passed through the `tpl` function to allow templating
    tls: []
  #    - hosts:
  #       - loki.example.com
  #      secretName: loki-distributed-tls

  ######################################################################################################################
  #
  # Migration
  #
  ######################################################################################################################

  # -- Options that may be necessary when performing a migration from another helm chart
  migrate:
    # -- When migrating from a distributed chart like loki-distributed or enterprise-logs
    fromDistributed:
      # -- Set to true if migrating from a distributed helm chart
      enabled: false
      # -- If migrating from a distributed service, provide the distributed deployment's
      # memberlist service DNS so the new deployment can join its ring.
      memberlistService: ""


  ######################################################################################################################
  #
  # Microservices Mode
  #
  # For large Loki deployments ingesting more than 1 TB/day
  #
  ######################################################################################################################

  # -- Configuration for the ingester
  ingester:
    # -- Number of replicas for the ingester, when zoneAwareReplication.enabled is true, the total
    # number of replicas will match this value with each zone having 1/3rd of the total replicas.
    replicas: 3
    # -- hostAliases to add
    hostAliases: []
    #  - ip: 1.2.3.4
    #    hostnames:
    #      - domain.tld
    autoscaling:
      # -- Enable autoscaling for the ingester
      enabled: false
      # -- Minimum autoscaling replicas for the ingester
      minReplicas: 1
      # -- Maximum autoscaling replicas for the ingester
      maxReplicas: 3
      # -- Target CPU utilisation percentage for the ingester
      targetCPUUtilizationPercentage: 60
      # -- Target memory utilisation percentage for the ingester
      targetMemoryUtilizationPercentage: null
      # -- Allows one to define custom metrics using the HPA/v2 schema (for example, Pods, Object or External metrics)
      customMetrics: []
      # - type: Pods
      #   pods:
      #     metric:
      #       name: loki_lines_total
      #     target:
      #       type: AverageValue
      #       averageValue: 10k
      behavior:
        # -- Enable autoscaling behaviours
        enabled: false
        # -- define scale down policies, must conform to HPAScalingRules
        scaleDown: {}
        # -- define scale up policies, must conform to HPAScalingRules
        scaleUp: {}

    # -- Command to execute instead of defined in Docker image
    command: null

    priorityClassName: null

    # -- Labels for ingester pods
    podLabels: {}

    # -- Annotations for ingester pods
    podAnnotations: {}

    # -- The name of the PriorityClass for ingester pods
    # -- Labels for ingestor service
    serviceLabels: {}

    # -- Annotations for ingestor service
    serviceAnnotations: {}

    # -- Additional CLI args for the ingester
    extraArgs:
      - -config.expand-env=true

    # -- Environment variables to add to the ingester pods
    extraEnv: []

    # -- Environment variables from secrets or configmaps to add to the ingester pods
    extraEnvFrom:
      - secretRef:
            name: loki-core


    # -- Volume mounts to add to the ingester pods
    extraVolumeMounts: []

    # -- Volumes to add to the ingester pods
    extraVolumes: []

    # -- Resource requests and limits for the ingester
    resources: {}

    # -- Containers to add to the ingester pods
    extraContainers: []

    # -- Init containers to add to the ingester pods
    initContainers: []

    # -- Grace period to allow the ingester to shutdown before it is killed. Especially for the ingestor,
    # this must be increased. It must be long enough so ingesters can be gracefully shutdown flushing/transferring
    # all data and to successfully leave the member ring on shutdown.
    terminationGracePeriodSeconds: 300

    # -- Lifecycle for the ingester container
    lifecycle: {}

    # -- topologySpread for ingester pods.
    # @default -- Defaults to allow skew no more than 1 node
    topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
        labelSelector:
          matchLabels:
            app.kubernetes.io/component: ingester

    # -- Affinity for ingester pods. Ignored if zoneAwareReplication is enabled.
    # @default -- Hard node anti-affinity
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/component: ingester
            topologyKey: kubernetes.io/hostname
    # -- Pod Disruption Budget maxUnavailable
    maxUnavailable: 1
    # -- Node selector for ingester pods
    nodeSelector: {}
    # -- Tolerations for ingester pods
    tolerations: []
    # -- readiness probe settings for ingester pods. If empty, use `loki.readinessProbe`
    readinessProbe: {}
    # -- liveness probe settings for ingester pods. If empty use `loki.livenessProbe`
    livenessProbe: {}
    # -- UpdateStrategy for the ingester StatefulSets.
    updateStrategy:
      # -- One of  'OnDelete' or 'RollingUpdate'
      type: RollingUpdate
      # -- Optional for updateStrategy.type=RollingUpdate. See [Partitioned rolling updates](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#partitions) in the StatefulSet docs for details.
      # rollingUpdate:
      #   partition: 0
    persistence:
      # -- Enable creating PVCs which is required when using boltdb-shipper
      enabled: false
      # -- Use emptyDir with ramdisk for storage. **Please note that all data in ingester will be lost on pod restart**
      inMemory: false
      # -- List of the ingester PVCs
      # @notationType -- list
      claims:
        - name: data
          size: 10Gi
          #   -- Storage class to be used.
          #   If defined, storageClassName: <storageClass>.
          #   If set to "-", storageClassName: "", which disables dynamic provisioning.
          #   If empty or set to null, no storageClassName spec is
          #   set, choosing the default provisioner (gp2 on AWS, standard on GKE, AWS, and OpenStack).
          storageClass: null
          # - name: wal
          #   size: 150Gi
      # -- Enable StatefulSetAutoDeletePVC feature
      enableStatefulSetAutoDeletePVC: false
      whenDeleted: Retain
      whenScaled: Retain
    # -- Adds the appProtocol field to the ingester service. This allows ingester to work with istio protocol selection.
    appProtocol:
      # -- Set the optional grpc service protocol. Ex: "grpc", "http2" or "https"
      grpc: ""
    # -- Enabling zone awareness on ingesters will create 3 statefulests where all writes will send a replica to each zone.
    # This is primarily intended to accelerate rollout operations by allowing for multiple ingesters within a single
    # zone to be shutdown and restart simultaneously (the remaining 2 zones will be guaranteed to have at least one copy
    # of the data).
    # Note: This can be used to run Loki over multiple cloud provider availability zones however this is not currently
    # recommended as Loki is not optimized for this and cross zone network traffic costs can become extremely high
    # extremely quickly. Even with zone awareness enabled, it is recommended to run Loki in a single availability zone.
    zoneAwareReplication:
      # -- Enable zone awareness.
      enabled: true
      # -- The percent of replicas in each zone that will be restarted at once. In a value of 0-100
      maxUnavailablePct: 33
      # -- zoneA configuration
      zoneA:
        # -- optionally define a node selector for this zone
        nodeSelector: null
        # -- optionally define extra affinity rules, by default different zones are not allowed to schedule on the same host
        extraAffinity: {}
        # -- Specific annotations to add to zone A statefulset
        annotations: {}
        # -- Specific annotations to add to zone A pods
        podAnnotations: {}
      zoneB:
        # -- optionally define a node selector for this zone
        nodeSelector: null
        # -- optionally define extra affinity rules, by default different zones are not allowed to schedule on the same host
        extraAffinity: {}
        # -- Specific annotations to add to zone B statefulset
        annotations: {}
        # -- Specific annotations to add to zone B pods
        podAnnotations: {}
      zoneC:
        # -- optionally define a node selector for this zone
        nodeSelector: null
        # -- optionally define extra affinity rules, by default different zones are not allowed to schedule on the same host
        extraAffinity: {}
        # -- Specific annotations to add to zone C statefulset
        annotations: {}
        # -- Specific annotations to add to zone C pods
        podAnnotations: {}
      # -- The migration block allows migrating non zone aware ingesters to zone aware ingesters.
      migration:
        enabled: false
        excludeDefaultZone: false
        readPath: false
        writePath: false

    # optionally allow adding arbitrary prefix to the ingester rollout-group label
    rolloutGroupPrefix: null
    # optionally allow adding 'loki-' prefix to ingester name label
    addIngesterNamePrefix: false

  # --  Configuration for the distributor
  distributor:
    # -- Number of replicas for the distributor
    replicas: 3

    maxUnavailable: 2

    # -- Additional CLI args for the ingester
    extraArgs:
      - -config.expand-env=true

    extraEnv:
      - name: S3_ENDPOINT
        valueFrom:
          secretKeyRef:
            name: loki-core
            key: S3URI

    extraEnvFrom:
      - secretRef:
            name: loki-core-s3



  # --  Configuration for the querier
  querier:
    # -- Number of replicas for the querier
    replicas: 3

    maxUnavailable: 2

    # -- Additional CLI args for the ingester
    extraArgs:
      - -config.expand-env=true

    extraEnv:
      - name: S3_ENDPOINT
        valueFrom:
          secretKeyRef:
            name: loki-core
            key: S3URI

    extraEnvFrom:
      - secretRef:
            name: loki-core-s3


    persistence:
      # -- Enable creating PVCs for the querier cache
      enabled: false
      # -- Size of persistent disk
      size: 10Gi
      # -- Storage class to be used.
      # If defined, storageClassName: <storageClass>.
      # If set to "-", storageClassName: "", which disables dynamic provisioning.
      # If empty or set to null, no storageClassName spec is
      # set, choosing the default provisioner (gp2 on AWS, standard on GKE, AWS, and OpenStack).
      storageClass: null
      # -- Annotations for querier PVCs
      annotations: {}
  
  # -- Configuration for the query-frontend
  queryFrontend:
    # -- Number of replicas for the query-frontend
    replicas: 2
    maxUnavailable: 1

    # -- Additional CLI args for the ingester
    extraArgs:
      - -config.expand-env=true

    extraEnv:
      - name: S3_ENDPOINT
        valueFrom:
          secretKeyRef:
            name: loki-core
            key: S3URI

    extraEnvFrom:
      - secretRef:
            name: loki-core-s3


  # -- Configuration for the query-scheduler
  queryScheduler:
    # -- Number of replicas for the query-scheduler.
    # It should be lower than `-querier.max-concurrent` to avoid generating back-pressure in queriers;
    # it's also recommended that this value evenly divides the latter
    replicas: 2

    # -- Additional CLI args for the ingester
    extraArgs:
      - -config.expand-env=true

    extraEnv:
      - name: S3_ENDPOINT
        valueFrom:
          secretKeyRef:
            name: loki-core
            key: S3URI

    extraEnvFrom:
      - secretRef:
            name: loki-core-s3


  # -- Configuration for the index-gateway
  indexGateway:
    # -- Number of replicas for the index-gateway
    replicas: 2
    # -- Whether the index gateway should join the memberlist hashring
    joinMemberlist: true

    maxUnavailable: 1

    # -- Additional CLI args for the ingester
    extraArgs:
      - -config.expand-env=true

    extraEnv:
      - name: S3_ENDPOINT
        valueFrom:
          secretKeyRef:
            name: loki-core
            key: S3URI

    extraEnvFrom:
      - secretRef:
          name: loki-core-s3

    
    persistence:
      # -- Enable creating PVCs which is required when using boltdb-shipper
      enabled: false
      # -- Use emptyDir with ramdisk for storage. **Please note that all data in indexGateway will be lost on pod restart**
      inMemory: false
      # -- Size of persistent or memory disk
      size: 10Gi
      # -- Storage class to be used.
      # If defined, storageClassName: <storageClass>.
      # If set to "-", storageClassName: "", which disables dynamic provisioning.
      # If empty or set to null, no storageClassName spec is
      # set, choosing the default provisioner (gp2 on AWS, standard on GKE, AWS, and OpenStack).
      storageClass: null
      # -- Annotations for index gateway PVCs
      annotations: {}
      # -- Enable StatefulSetAutoDeletePVC feature
      enableStatefulSetAutoDeletePVC: false
      whenDeleted: Retain
      whenScaled: Retain
    
  # -- Configuration for the compactor
  compactor:
    # -- Number of replicas for the compactor
    replicas: 1

    # -- Additional CLI args for the ingester
    extraArgs:
      - -config.expand-env=true

    extraEnv:
      - name: S3_ENDPOINT
        valueFrom:
          secretKeyRef:
            name: loki-core
            key: S3URI

    extraEnvFrom:
      - secretRef:
            name: loki-core-s3

  
  # -- Configuration for the bloom-gateway
  bloomGateway:
    # -- Number of replicas for the bloom-gateway
    replicas: 0

  # -- Configuration for the bloom-planner
  bloomPlanner:
    # -- Number of replicas for the bloom-planner
    replicas: 0

  # -- Configuration for the bloom-builder
  bloomBuilder:
    # -- Number of replicas for the bloom-builder
    replicas: 0

  # -- Configuration for the pattern ingester
  patternIngester:
    # -- Number of replicas for the pattern ingester
    replicas: 0
    # -- hostAliases to add
    hostAliases: []
    #  - ip: 1.2.3.4
    #    hostnames:
    #      - domain.tld
    image:
      # -- The Docker registry for the pattern ingester image. Overrides `loki.image.registry`
      registry: null
      # -- Docker image repository for the pattern ingester image. Overrides `loki.image.repository`
      repository: null
      # -- Docker image tag for the pattern ingester image. Overrides `loki.image.tag`
      tag: null
    # -- Command to execute instead of defined in Docker image
    command: null
    # -- The name of the PriorityClass for pattern ingester pods
    priorityClassName: null
    # -- Labels for pattern ingester pods
    podLabels: {}
    # -- Annotations for pattern ingester pods
    podAnnotations: {}
    # -- Affinity for pattern ingester pods.
    # @default -- Hard node anti-affinity
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/component: pattern-ingester
            topologyKey: kubernetes.io/hostname
    # -- Labels for pattern ingester service
    serviceLabels: {}
    # -- Annotations for pattern ingester service
    serviceAnnotations: {}
    # -- Additional CLI args for the pattern ingester
    extraArgs: []
    # -- Environment variables to add to the pattern ingester pods
    extraEnv: []
    # -- Environment variables from secrets or configmaps to add to the pattern ingester pods
    extraEnvFrom: []
    # -- Volume mounts to add to the pattern ingester pods
    extraVolumeMounts: []
    # -- Volumes to add to the pattern ingester pods
    extraVolumes: []
    # -- readiness probe settings for ingester pods. If empty, use `loki.readinessProbe`
    readinessProbe: {}
    # -- liveness probe settings for ingester pods. If empty use `loki.livenessProbe`
    livenessProbe: {}
    # -- Resource requests and limits for the pattern ingester
    resources: {}
    # -- Containers to add to the pattern ingester pods
    extraContainers: []
    # -- Init containers to add to the pattern ingester pods
    initContainers: []
    # -- Grace period to allow the pattern ingester to shutdown before it is killed
    terminationGracePeriodSeconds: 30
    # -- Node selector for pattern ingester pods
    nodeSelector: {}
    # -- Topology Spread Constraints for pattern ingester pods
    topologySpreadConstraints: []
    # -- Tolerations for pattern ingester pods
    tolerations: []
    # -- Set the optional grpc service protocol. Ex: "grpc", "http2" or "https"
    appProtocol:
      grpc: ""
    persistence:
      # -- Enable creating PVCs for the pattern ingester
      enabled: false
      # -- Size of persistent disk
      size: 10Gi
      # -- Storage class to be used.
      # If defined, storageClassName: <storageClass>.
      # If set to "-", storageClassName: "", which disables dynamic provisioning.
      # If empty or set to null, no storageClassName spec is
      # set, choosing the default provisioner (gp2 on AWS, standard on GKE, AWS, and OpenStack).
      storageClass: null
      # -- Annotations for pattern ingester PVCs
      annotations: {}
      # -- List of the pattern ingester PVCs
      # @notationType -- list
      claims:
        - name: data
          size: 10Gi
          #   -- Storage class to be used.
          #   If defined, storageClassName: <storageClass>.
          #   If set to "-", storageClassName: "", which disables dynamic provisioning.
          #   If empty or set to null, no storageClassName spec is
          #   set, choosing the default provisioner (gp2 on AWS, standard on GKE, AWS, and OpenStack).
          storageClass: null
          # - name: wal
          #   size: 150Gi
      # -- Enable StatefulSetAutoDeletePVC feature
      enableStatefulSetAutoDeletePVC: false
      whenDeleted: Retain
      whenScaled: Retain
    serviceAccount:
      create: false
      # -- The name of the ServiceAccount to use for the pattern ingester.
      # If not set and create is true, a name is generated by appending
      # "-pattern-ingester" to the common ServiceAccount.
      name: null
      # -- Image pull secrets for the pattern ingester service account
      imagePullSecrets: []
      # -- Annotations for the pattern ingester service account
      annotations: {}
      # -- Set this toggle to false to opt out of automounting API credentials for the service account
      automountServiceAccountToken: true

  # -- Configuration for the ruler
  ruler:
    # -- The ruler component is optional and can be disabled if desired.
    enabled: true
    # -- Number of replicas for the ruler
    replicas: 0

    persistence:
      # -- Enable creating PVCs which is required when using recording rules
      enabled: false
      # -- Size of persistent disk
      size: 10Gi
      # -- Storage class to be used.
      # If defined, storageClassName: <storageClass>.
      # If set to "-", storageClassName: "", which disables dynamic provisioning.
      # If empty or set to null, no storageClassName spec is
      # set, choosing the default provisioner (gp2 on AWS, standard on GKE, AWS, and OpenStack).
      storageClass: null
      # -- Annotations for ruler PVCs
      annotations: {}

    # -- Directories containing rules files
    directories: {}
    # tenant_foo:
    #   rules1.txt: |
    #     groups:
    #       - name: should_fire
    #         rules:
    #           - alert: HighPercentageError
    #             expr: |
    #               sum(rate({app="foo", env="production"} |= "error" [5m])) by (job)
    #                 /
    #               sum(rate({app="foo", env="production"}[5m])) by (job)
    #                 > 0.05
    #             for: 10m
    #             labels:
    #               severity: warning
    #             annotations:
    #               summary: High error rate
    #       - name: credentials_leak
    #         rules:
    #           - alert: http-credentials-leaked
    #             annotations:
    #               message: "{{ $labels.job }} is leaking http basic auth credentials."
    #             expr: 'sum by (cluster, job, pod) (count_over_time({namespace="prod"} |~ "http(s?)://(\\w+):(\\w+)@" [5m]) > 0)'
    #             for: 10m
    #             labels:
    #               severity: critical
    #   rules2.txt: |
    #     groups:
    #       - name: example
    #         rules:
    #         - alert: HighThroughputLogStreams
    #           expr: sum by(container) (rate({job=~"loki-dev/.*"}[1m])) > 1000
    #           for: 2m
    # tenant_bar:
    #   rules1.txt: |
    #     groups:
    #       - name: should_fire
    #         rules:
    #           - alert: HighPercentageError
    #             expr: |
    #               sum(rate({app="foo", env="production"} |= "error" [5m])) by (job)
    #                 /
    #               sum(rate({app="foo", env="production"}[5m])) by (job)
    #                 > 0.05
    #             for: 10m
    #             labels:
    #               severity: warning
    #             annotations:
    #               summary: High error rate
    #       - name: credentials_leak
    #         rules:
    #           - alert: http-credentials-leaked
    #             annotations:
    #               message: "{{ $labels.job }} is leaking http basic auth credentials."
    #             expr: 'sum by (cluster, job, pod) (count_over_time({namespace="prod"} |~ "http(s?)://(\\w+):(\\w+)@" [5m]) > 0)'
    #             for: 10m
    #             labels:
    #               severity: critical
    #   rules2.txt: |
    #     groups:
    #       - name: example
    #         rules:
    #         - alert: HighThroughputLogStreams
    #           expr: sum by(container) (rate({job=~"loki-dev/.*"}[1m])) > 1000
    #           for: 2m

  # -- Configuration for the overrides-exporter
  overridesExporter:
    # -- The overrides-exporter component is optional and can be disabled if desired.
    enabled: false
    # -- Number of replicas for the overrides-exporter
    replicas: 0
    # -- hostAliases to add
    hostAliases: []
    #  - ip: 1.2.3.4
    #    hostnames:
    #      - domain.tld
    image:
      # -- The Docker registry for the overrides-exporter image. Overrides `loki.image.registry`
      registry: null
      # -- Docker image repository for the overrides-exporter image. Overrides `loki.image.repository`
      repository: null
      # -- Docker image tag for the overrides-exporter image. Overrides `loki.image.tag`
      tag: null
    # -- Command to execute instead of defined in Docker image
    command: null
    # -- The name of the PriorityClass for overrides-exporter pods
    priorityClassName: null
    # -- Labels for overrides-exporter pods
    podLabels: {}
    # -- Annotations for overrides-exporter pods
    podAnnotations: {}
    # -- Labels for overrides-exporter service
    serviceLabels: {}
    # -- Annotations for overrides-exporter service
    serviceAnnotations: {}
    # -- Additional CLI args for the overrides-exporter
    extraArgs: []
    # -- Environment variables to add to the overrides-exporter pods
    extraEnv: []
    # -- Environment variables from secrets or configmaps to add to the overrides-exporter pods
    extraEnvFrom: []
    # -- Volume mounts to add to the overrides-exporter pods
    extraVolumeMounts: []
    # -- Volumes to add to the overrides-exporter pods
    extraVolumes: []
    # -- Resource requests and limits for the overrides-exporter
    resources: {}
    # -- Containers to add to the overrides-exporter pods
    extraContainers: []
    # -- Init containers to add to the overrides-exporter pods
    initContainers: []
    # -- Grace period to allow the overrides-exporter to shutdown before it is killed
    terminationGracePeriodSeconds: 300
    # -- Affinity for overrides-exporter pods.
    # @default -- Hard node anti-affinity
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/component: overrides-exporter
            topologyKey: kubernetes.io/hostname
    # -- Pod Disruption Budget maxUnavailable
    maxUnavailable: null
    # -- Node selector for overrides-exporter pods
    nodeSelector: {}
    # -- Topology Spread Constraints for overrides-exporter pods
    topologySpreadConstraints: []
    # -- Tolerations for overrides-exporter pods
    tolerations: []
    # -- Set the optional grpc service protocol. Ex: "grpc", "http2" or "https"
    appProtocol:
      grpc: ""

  memcached:
    # -- The SecurityContext override for memcached pods
    podSecurityContext:
      runAsNonRoot: true
      runAsUser: 11211
      runAsGroup: 11211
      fsGroup: 11211

    # -- The name of the PriorityClass for memcached pods
    priorityClassName: null

    # -- The SecurityContext for memcached containers
    containerSecurityContext:
      readOnlyRootFilesystem: true
      capabilities:
        drop: [ALL]
      allowPrivilegeEscalation: false

  memcachedExporter:
    # -- Whether memcached metrics should be exported
    enabled: false
    image:
      repository: prom/memcached-exporter
      tag: v0.15.0
      pullPolicy: IfNotPresent
    resources:
      requests: {}
      limits: {}
    # -- The SecurityContext for memcached exporter containers
    containerSecurityContext:
      readOnlyRootFilesystem: true
      capabilities:
        drop: [ALL]
      allowPrivilegeEscalation: false
    # -- Extra args to add to the exporter container.
    # Example:
    # extraArgs:
    #   memcached.tls.enable: true
    #   memcached.tls.cert-file: /certs/cert.crt
    #   memcached.tls.key-file: /certs/cert.key
    #   memcached.tls.ca-file: /certs/ca.crt
    #   memcached.tls.insecure-skip-verify: false
    #   memcached.tls.server-name: memcached
    extraArgs: {}
  resultsCache:
    # -- Specifies whether memcached based results-cache should be enabled
    enabled: true
    # -- Specify how long cached results should be stored in the results-cache before being expired
    defaultValidity: 12h
    # -- Memcached operation timeout
    timeout: 500ms
    # -- Total number of results-cache replicas
    replicas: 1
    # -- Port of the results-cache service
    port: 11211
    # -- Amount of memory allocated to results-cache for object storage (in MB).
    allocatedMemory: 1024
    # -- Maximum item results-cache for memcached (in MB).
    maxItemMemory: 5
    # -- Maximum number of connections allowed
    connectionLimit: 16384
    # -- Max memory to use for cache write back
    writebackSizeLimit: 500MB
    # -- Max number of objects to use for cache write back
    writebackBuffer: 500000
    # -- Number of parallel threads for cache write back
    writebackParallelism: 1
    # -- Extra init containers for results-cache pods
    initContainers: []
    # -- Annotations for the results-cache pods
    annotations: {}
    # -- Node selector for results-cache pods
    nodeSelector: {}
    # -- Affinity for results-cache pods
    affinity: {}
    # -- topologySpreadConstraints allows to customize the default topologySpreadConstraints. This can be either a single dict as shown below or a slice of topologySpreadConstraints.
    # labelSelector is taken from the constraint itself (if it exists) or is generated by the chart using the same selectors as for services.
    topologySpreadConstraints: []
    #  maxSkew: 1
    #  topologyKey: kubernetes.io/hostname
    #  whenUnsatisfiable: ScheduleAnyway
    # -- Tolerations for results-cache pods
    tolerations: []
    # -- Pod Disruption Budget
    podDisruptionBudget:
      maxUnavailable: 1
    # -- The name of the PriorityClass for results-cache pods
    priorityClassName: null
    # -- Labels for results-cache pods
    podLabels: {}
    # -- Annotations for results-cache pods
    podAnnotations: {}
    # -- Management policy for results-cache pods
    podManagementPolicy: Parallel
    # -- Grace period to allow the results-cache to shutdown before it is killed
    terminationGracePeriodSeconds: 60
    # -- Stateful results-cache strategy
    statefulStrategy:
      type: RollingUpdate
    # -- Add extended options for results-cache memcached container. The format is the same as for the memcached -o/--extend flag.
    # Example:
    # extraExtendedOptions: 'tls,modern,track_sizes'
    extraExtendedOptions: ""
    # -- Additional CLI args for results-cache
    extraArgs: {}
    # -- Additional containers to be added to the results-cache pod.
    extraContainers: []
    # -- Additional volumes to be added to the results-cache pod (applies to both memcached and exporter containers).
    # Example:
    # extraVolumes:
    # - name: extra-volume
    #   secret:
    #    secretName: extra-volume-secret
    extraVolumes: []
    # -- Additional volume mounts to be added to the results-cache pod (applies to both memcached and exporter containers).
    # Example:
    # extraVolumeMounts:
    # - name: extra-volume
    #   mountPath: /etc/extra-volume
    #   readOnly: true
    extraVolumeMounts: []
    # -- Resource requests and limits for the results-cache
    # By default a safe memory limit will be requested based on allocatedMemory value (floor (* 1.2 allocatedMemory)).
    resources: null
    # -- Service annotations and labels
    service:
      annotations: {}
      labels: {}
    # -- Persistence settings for the results-cache
    persistence:
      # -- Enable creating PVCs for the results-cache
      enabled: false
      # -- Size of persistent disk, must be in G or Gi
      storageSize: 10G
      # -- Storage class to be used.
      # If defined, storageClassName: <storageClass>.
      # If set to "-", storageClassName: "", which disables dynamic provisioning.
      # If empty or set to null, no storageClassName spec is
      # set, choosing the default provisioner (gp2 on AWS, standard on GKE, AWS, and OpenStack).
      storageClass: null
      # -- Volume mount path
      mountPath: /data
  chunksCache:
    # -- Specifies whether memcached based chunks-cache should be enabled
    enabled: true
    # -- Batchsize for sending and receiving chunks from chunks cache
    batchSize: 4
    # -- Parallel threads for sending and receiving chunks from chunks cache
    parallelism: 5
    # -- Memcached operation timeout
    timeout: 2000ms
    # -- Specify how long cached chunks should be stored in the chunks-cache before being expired
    defaultValidity: 0s
    # -- Total number of chunks-cache replicas
    replicas: 1
    # -- Port of the chunks-cache service
    port: 11211
    # -- Amount of memory allocated to chunks-cache for object storage (in MB).
    allocatedMemory: 8192
    # -- Maximum item memory for chunks-cache (in MB).
    maxItemMemory: 5
    # -- Maximum number of connections allowed
    connectionLimit: 16384
    # -- Max memory to use for cache write back
    writebackSizeLimit: 500MB
    # -- Max number of objects to use for cache write back
    writebackBuffer: 500000
    # -- Number of parallel threads for cache write back
    writebackParallelism: 1
    # -- Extra init containers for chunks-cache pods
    initContainers: []
    # -- Annotations for the chunks-cache pods
    annotations: {}
    # -- Node selector for chunks-cache pods
    nodeSelector: {}
    # -- Affinity for chunks-cache pods
    affinity: {}
    # -- topologySpreadConstraints allows to customize the default topologySpreadConstraints. This can be either a single dict as shown below or a slice of topologySpreadConstraints.
    # labelSelector is taken from the constraint itself (if it exists) or is generated by the chart using the same selectors as for services.
    topologySpreadConstraints: []
    #  maxSkew: 1
    #  topologyKey: kubernetes.io/hostname
    #  whenUnsatisfiable: ScheduleAnyway
    # -- Tolerations for chunks-cache pods
    tolerations: []
    # -- Pod Disruption Budget
    podDisruptionBudget:
      maxUnavailable: 1
    # -- The name of the PriorityClass for chunks-cache pods
    priorityClassName: null
    # -- Labels for chunks-cache pods
    podLabels: {}
    # -- Annotations for chunks-cache pods
    podAnnotations: {}
    # -- Management policy for chunks-cache pods
    podManagementPolicy: Parallel
    # -- Grace period to allow the chunks-cache to shutdown before it is killed
    terminationGracePeriodSeconds: 60
    # -- Stateful chunks-cache strategy
    statefulStrategy:
      type: RollingUpdate
    # -- Add extended options for chunks-cache memcached container. The format is the same as for the memcached -o/--extend flag.
    # Example:
    # extraExtendedOptions: 'tls,no_hashexpand'
    extraExtendedOptions: ""
    # -- Additional CLI args for chunks-cache
    extraArgs: {}
    # -- Additional containers to be added to the chunks-cache pod.
    extraContainers: []
    # -- Additional volumes to be added to the chunks-cache pod (applies to both memcached and exporter containers).
    # Example:
    # extraVolumes:
    # - name: extra-volume
    #   secret:
    #    secretName: extra-volume-secret
    extraVolumes: []
    # -- Additional volume mounts to be added to the chunks-cache pod (applies to both memcached and exporter containers).
    # Example:
    # extraVolumeMounts:
    # - name: extra-volume
    #   mountPath: /etc/extra-volume
    #   readOnly: true
    extraVolumeMounts: []
    # -- Resource requests and limits for the chunks-cache
    # By default a safe memory limit will be requested based on allocatedMemory value (floor (* 1.2 allocatedMemory)).
    resources: null
    # -- Service annotations and labels
    service:
      annotations: {}
      labels: {}
    # -- Persistence settings for the chunks-cache
    persistence:
      # -- Enable creating PVCs for the chunks-cache
      enabled: false
      # -- Size of persistent disk, must be in G or Gi
      storageSize: 10G
      # -- Storage class to be used.
      # If defined, storageClassName: <storageClass>.
      # If set to "-", storageClassName: "", which disables dynamic provisioning.
      # If empty or set to null, no storageClassName spec is
      # set, choosing the default provisioner (gp2 on AWS, standard on GKE, AWS, and OpenStack).
      storageClass: null
      # -- Volume mount path
      mountPath: /data
  ######################################################################################################################
  #
  # Subchart configurations
  #
  ######################################################################################################################
  # -- Setting for the Grafana Rollout Operator https://github.com/grafana/helm-charts/tree/main/charts/rollout-operator
  rollout_operator:
    enabled: false
    # -- podSecurityContext is the pod security context for the rollout operator.
    # When installing on OpenShift, override podSecurityContext settings with
    #
    # rollout_operator:
    #   podSecurityContext:
    #     fsGroup: null
    #     runAsGroup: null
    #     runAsUser: null
    podSecurityContext:
      fsGroup: 10001
      runAsGroup: 10001
      runAsNonRoot: true
      runAsUser: 10001
      seccompProfile:
        type: RuntimeDefault
    # Set the container security context
    securityContext:
      readOnlyRootFilesystem: true
      capabilities:
        drop: [ALL]
      allowPrivilegeEscalation: false

  # -- Configuration for the minio subchart
  minio:
    enabled: false

  # Create extra manifests via values. Would be passed through `tpl` for templating
  # objects can also be provided as multiline strings, useful for templating field names
  extraObjects: []
  # - apiVersion: v1
  #   kind: ConfigMap
  #   metadata:
  #     name: loki-alerting-rules
  #   data:
  #     loki-alerting-rules.yaml: |-
  #       groups:
  #         - name: example
  #           rules:
  #           - alert: example
  #             expr: |
  #               sum(count_over_time({app="loki"} |~ "error")) > 0
  #             for: 3m
  #             labels:
  #               severity: warning
  #               category: logs
  #             annotations:
  #               message: "loki has encountered errors"
  # - |
  #     apiVersion: v1
  #     kind: Secret
  #     type: Opaque
  #     metadata:
  #       name: loki-distributed-basic-auth
  #     data:
  #       {{- range .Values.loki.tenants }}
  #       {{ .name }}: {{ b64enc .password | quote }}
  #       {{- end }}

  sidecar:
    image:
      # -- The Docker registry and image for the k8s sidecar
      repository: kiwigrid/k8s-sidecar
      # -- Docker image tag
      tag: 1.29.0
      # -- Docker image sha. If empty, no sha will be used
      sha: ""
      # -- Docker image pull policy
      pullPolicy: IfNotPresent
    # -- Resource requests and limits for the sidecar
    resources: {}
    #   limits:
    #     cpu: 100m
    #     memory: 100Mi
    #   requests:
    #     cpu: 50m
    #     memory: 50Mi
    # -- The SecurityContext for the sidecar.
    securityContext:
      readOnlyRootFilesystem: true
      capabilities:
        drop:
          - ALL
      allowPrivilegeEscalation: false
    # -- Set to true to skip tls verification for kube api calls.
    skipTlsVerify: false
    # -- Ensure that rule files aren't conflicting and being overwritten by prefixing their name with the namespace they are defined in.
    enableUniqueFilenames: false
    # -- Readiness probe definition. Probe is disabled on the sidecar by default.
    readinessProbe: {}
    # -- Liveness probe definition. Probe is disabled on the sidecar by default.
    livenessProbe: {}
    rules:
      # -- Whether or not to create a sidecar to ingest rule from specific ConfigMaps and/or Secrets.
      enabled: true
      # -- Label that the configmaps/secrets with rules will be marked with.
      label: loki_rule
      # -- Label value that the configmaps/secrets with rules will be set to.
      labelValue: ""
      # -- Folder into which the rules will be placed.
      folder: /rules
      # -- Comma separated list of namespaces. If specified, the sidecar will search for config-maps/secrets inside these namespaces.
      # Otherwise the namespace in which the sidecar is running will be used.
      # It's also possible to specify 'ALL' to search in all namespaces.
      searchNamespace: null
      # -- Method to use to detect ConfigMap changes. With WATCH the sidecar will do a WATCH request, with SLEEP it will list all ConfigMaps, then sleep for 60 seconds.
      watchMethod: WATCH
      # -- Search in configmap, secret, or both.
      resource: both
      # -- Absolute path to the shell script to execute after a configmap or secret has been reloaded.
      script: null
      # -- WatchServerTimeout: request to the server, asking it to cleanly close the connection after that.
      # defaults to 60sec; much higher values like 3600 seconds (1h) are feasible for non-Azure K8S.
      watchServerTimeout: 60
      #
      # -- WatchClientTimeout: is a client-side timeout, configuring your local socket.
      # If you have a network outage dropping all packets with no RST/FIN,
      # this is how long your client waits before realizing & dropping the connection.
      # Defaults to 66sec.
      watchClientTimeout: 60
      # -- Log level of the sidecar container.
      logLevel: INFO
